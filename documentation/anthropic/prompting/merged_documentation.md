# Merged Prompting Documentation
Generated by merge_prompting_docs.py

Reasoning best practices
========================

Learn when to use reasoning models and how they compare to GPT models.

OpenAI offers two types of models: [reasoning models](/docs/models#o4-mini) (o3 and o4-mini, for example) and [GPT models](/docs/models#gpt-4.1) (like GPT-4.1). These model families behave differently.

This guide covers:

1.  The difference between our reasoning and non-reasoning GPT models
2.  When to use our reasoning models
3.  How to prompt reasoning models effectively

Read more about [reasoning models](/docs/guides/reasoning) and how they work.

Reasoning models vs. GPT models
-------------------------------

Compared to GPT models, our o-series models excel at different tasks and require different prompts. One model family isn't better than the other,they're just different.

We trained our o-series models (“the planners”) to think longer and harder about complex tasks, making them effective at strategizing, planning solutions to complex problems, and making decisions based on large volumes of ambiguous information. These models can also execute tasks with high accuracy and precision, making them ideal for domains that would otherwise require a human expert,like math, science, engineering, financial services, and legal services.

On the other hand, our lower-latency, more cost-efficient GPT models (“the workhorses”) are designed for straightforward execution. An application might use o-series models to plan out the strategy to solve a problem, and use GPT models to execute specific tasks, particularly when speed and cost are more important than perfect accuracy.

### How to choose

What's most important for your use case?

*   **Speed and cost** → GPT models are faster and tend to cost less
*   **Executing well defined tasks** → GPT models handle explicitly defined tasks well
*   **Accuracy and reliability** → o-series models are reliable decision makers
*   **Complex problem-solving** → o-series models work through ambiguity and complexity

If speed and cost are the most important factors when completing your tasks _and_ your use case is made up of straightforward, well defined tasks, then our GPT models are the best fit for you. However, if accuracy and reliability are the most important factors _and_ you have a very complex, multistep problem to solve, our o-series models are likely right for you.

Most AI workflows will use a combination of both models,o-series for agentic planning and decision-making, GPT series for task execution.

![GPT models pair well with o-series models](https://cdn.openai.com/API/docs/images/customer-service-example.png)

_Our GPT-4o and GPT-4o mini models triage order details with customer information, identify the order issues and the return policy, and then feed all of these data points into o3-mini to make the final decision about the viability of the return based on policy._

When to use our reasoning models
--------------------------------

Here are a few patterns of successful usage that we’ve observed from customers and internally at OpenAI. This isn't a comprehensive review of all possible use cases but, rather, some practical guidance for testing our o-series models.

[Ready to use a reasoning model? Skip to the quickstart →](/docs/guides/reasoning)

### 1\. Navigating ambiguous tasks

Reasoning models are particularly good at taking limited information or disparate pieces of information and with a simple prompt, understanding the user’s intent and handling any gaps in the instructions. In fact, reasoning models will often ask clarifying questions before making uneducated guesses or attempting to fill information gaps.

> “o1’s reasoning capabilities enable our multi-agent platform Matrix to produce exhaustive, well-formatted, and detailed responses when processing complex documents. For example, o1 enabled Matrix to easily identify baskets available under the restricted payments capacity in a credit agreement, with a basic prompt. No former models are as performant. o1 yielded stronger results on 52% of complex prompts on dense Credit Agreements compared to other models.”
> 
>,[Hebbia](https://www.hebbia.com/), AI knowledge platform company for legal and finance

### 2\. Finding a needle in a haystack

When you’re passing large amounts of unstructured information, reasoning models are great at understanding and pulling out only the most relevant information to answer a question.

> "To analyze a company's acquisition, o1 reviewed dozens of company documents,like contracts and leases,to find any tricky conditions that might affect the deal. The model was tasked with flagging key terms and in doing so, identified a crucial "change of control" provision in the footnotes: if the company was sold, it would have to pay off a $75 million loan immediately. o1's extreme attention to detail enables our AI agents to support finance professionals by identifying mission-critical information."
> 
>,[Endex](https://endex.ai/), AI financial intelligence platform

### 3\. Finding relationships and nuance across a large dataset

We’ve found that reasoning models are particularly good at reasoning over complex documents that have hundreds of pages of dense, unstructured information,things like legal contracts, financial statements, and insurance claims. The models are particularly strong at drawing parallels between documents and making decisions based on unspoken truths represented in the data.

> “Tax research requires synthesizing multiple documents to produce a final, cogent answer. We swapped GPT-4o for o1 and found that o1 was much better at reasoning over the interplay between documents to reach logical conclusions that were not evident in any one single document. As a result, we saw a 4x improvement in end-to-end performance by switching to o1,incredible.”
> 
>,[Blue J](https://www.bluej.com/), AI platform for tax research

Reasoning models are also skilled at reasoning over nuanced policies and rules, and applying them to the task at hand in order to reach a reasonable conclusion.

> "In financial analyses, analysts often tackle complex scenarios around shareholder equity and need to understand the relevant legal intricacies. We tested about 10 models from different providers with a challenging but common question: how does a fundraise affect existing shareholders, especially when they exercise their anti-dilution privileges? This required reasoning through pre- and post-money valuations and dealing with circular dilution loops,something top financial analysts would spend 20-30 minutes to figure out. We found that o1 and o3-mini can do this flawlessly! The models even produced a clear calculation table showing the impact on a $100k shareholder."
> 
> –[BlueFlame AI](https://www.blueflame.ai/), AI platform for investment management

### 4\. Multistep agentic planning

Reasoning models are critical to agentic planning and strategy development. We’ve seen success when a reasoning model is used as “the planner,” producing a detailed, multistep solution to a problem and then selecting and assigning the right GPT model (“the doer”) for each step, based on whether high intelligence or low latency is most important.

> “We use o1 as the planner in our agent infrastructure, letting it orchestrate other models in the workflow to complete a multistep task. We find o1 is really good at selecting data types and breaking down big questions into smaller chunks, enabling other models to focus on execution.”
> 
>,[Argon AI](https://argon-ai.com/), AI knowledge platform for the pharmaceutical industry

> “o1 powers many of our agentic workflows at Lindy, our AI assistant for work. The model uses function calling to pull information from your calendar or email and then can automatically help you schedule meetings, send emails, and manage other parts of your day-to-day tasks. We switched all of our agentic steps that used to cause issues to o1 and observing our agents becoming basically flawless overnight!”
> 
>,[Lindy.AI](http://Lindy.AI), AI assistant for work

### 5\. Visual reasoning

As of today, o1 is the only reasoning model that supports vision capabilities. What sets it apart from GPT-4o is that o1 can grasp even the most challenging visuals, like charts and tables with ambiguous structure or photos with poor image quality.

> “We automate risk and compliance reviews for millions of products online, including luxury jewelry dupes, endangered species, and controlled substances. GPT-4o reached 50% accuracy on our hardest image classification tasks. o1 achieved an impressive 88% accuracy without any modifications to our pipeline.”
> 
>,[SafetyKit](https://www.safetykit.com/), AI-powered risk and compliance platform

From our own internal testing, we’ve seen that o1 can identify fixtures and materials from highly detailed architectural drawings to generate a comprehensive bill of materials. One of the most surprising things we observed was that o1 can draw parallels across different images by taking a legend on one page of the architectural drawings and correctly applying it across another page without explicit instructions. Below you can see that, for the 4x4 PT wood posts, o1 recognized that "PT" stands for pressure treated based on the legend.

![o-series models correctly read architectural drawing details](https://cdn.openai.com/API/docs/images/architectural-drawing-example.png)

### 6\. Reviewing, debugging, and improving code quality

Reasoning models are particularly effective at reviewing and improving large amounts of code, often running code reviews in the background given the models’ higher latency.

> “We deliver automated AI Code Reviews on platforms like GitHub and GitLab. While code review process is not inherently latency-sensitive, it does require understanding the code diffs across multiple files. This is where o1 really shines,it's able to reliably detect minor changes to a codebase that could be missed by a human reviewer. We were able to increase product conversion rates by 3x after switching to o-series models.”
> 
>,[CodeRabbit](https://www.coderabbit.ai/), AI code review startup

While GPT-4o and GPT-4o mini may be better designed for writing code with their lower latency, we’ve also seen o3-mini spike on code production for use cases that are slightly less latency-sensitive.

> “o3-mini consistently produces high-quality, conclusive code, and very frequently arrives at the correct solution when the problem is well-defined, even for very challenging coding tasks. While other models may only be useful for small-scale, quick code iterations, o3-mini excels at planning and executing complex software design systems.”
> 
>,[Windsurf](https://codeium.com/), collaborative agentic AI-powered IDE, built by Codeium

### 7\. Evaluation and benchmarking for other model responses

We’ve also seen reasoning models do well in benchmarking and evaluating other model responses. Data validation is important for ensuring dataset quality and reliability, especially in sensitive fields like healthcare. Traditional validation methods use predefined rules and patterns, but advanced models like o1 and o3-mini can understand context and reason about data for a more flexible and intelligent approach to validation.

> "Many customers use LLM-as-a-judge as part of their eval process in Braintrust. For example, a healthcare company might summarize patient questions using a workhorse model like gpt-4o, then assess the summary quality with o1. One Braintrust customer saw the F1 score of a judge go from 0.12 with 4o to 0.74 with o1! In these use cases, they’ve found o1’s reasoning to be a game-changer in finding nuanced differences in completions, for the hardest and most complex grading tasks."
> 
>,[Braintrust](https://www.braintrust.dev/), AI evals platform

How to prompt reasoning models effectively
------------------------------------------

These models perform best with straightforward prompts. Some prompt engineering techniques, like instructing the model to "think step by step," may not enhance performance (and can sometimes hinder it). See best practices below, or [get started with prompt examples](/docs/guides/reasoning/advice-on-prompting#prompt-examples).

*   **Developer messages are the new system messages**: Starting with `o1-2024-12-17`, reasoning models support developer messages rather than system messages, to align with the chain of command behavior described in the [model spec](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command).
*   **Keep prompts simple and direct**: The models excel at understanding and responding to brief, clear instructions.
*   **Avoid chain-of-thought prompts**: Since these models perform reasoning internally, prompting them to "think step by step" or "explain your reasoning" is unnecessary.
*   **Use delimiters for clarity**: Use delimiters like markdown, XML tags, and section titles to clearly indicate distinct parts of the input, helping the model interpret different sections appropriately.
*   **Try zero shot first, then few shot if needed**: Reasoning models often don't need few-shot examples to produce good results, so try to write prompts without examples first. If you have more complex requirements for your desired output, it may help to include a few examples of inputs and desired outputs in your prompt. Just ensure that the examples align very closely with your prompt instructions, as discrepancies between the two may produce poor results.
*   **Provide specific guidelines**: If there are ways you explicitly want to constrain the model's response (like "propose a solution with a budget under $500"), explicitly outline those constraints in the prompt.
*   **Be very specific about your end goal**: In your instructions, try to give very specific parameters for a successful response, and encourage the model to keep reasoning and iterating until it matches your success criteria.
*   **Markdown formatting**: Starting with `o1-2024-12-17`, reasoning models in the API will avoid generating responses with markdown formatting. To signal to the model when you do want markdown formatting in the response, include the string `Formatting re-enabled` on the first line of your developer message.

How to keep costs low and accuracy high
---------------------------------------

With the introduction of `o3` and `o4-mini` models, persisted reasoning items in the Responses API are treated differently. Previously (for `o1`, `o3-mini`, `o1-mini` and `o1-preview`), reasoning items were always ignored in follow‑up API requests, even if they were included in the input items of the requests. With `o3` and `o4-mini`, some reasoning items adjacent to function calls are included in the model’s context to help improve model performance while using the least amount of reasoning tokens.

For the best results with this change, we recommend using the [Responses API](/docs/api-reference/responses) with the `store` parameter set to `true`, and passing in all reasoning items from previous requests (either using `previous_response_id`, or by taking all the output items from an older request and passing them in as input items for a new one). OpenAI will automatically include any relevant reasoning items in the model's context and ignore any irrelevant ones. In more advanced use‑cases where you’d like to manage what goes into the model's context more precisely, we recommend that you at least include all reasoning items between the latest function call and the previous user message. Doing this will ensure that the model doesn’t have to restart its reasoning when you respond to a function call, resulting in better function‑calling performance and lower overall token usage.

If you’re using the Chat Completions API, reasoning items are never included in the context of the model. This is because Chat Completions is a stateless API. This will result in slightly degraded model performance and greater reasoning token usage in complex agentic cases involving many function calls. In instances where complex multiple function calling is not involved, there should be no degradation in performance regardless of the API being used.

Other resources
---------------

For more inspiration, visit the [OpenAI Cookbook](https://cookbook.openai.com), which contains example code and links to third-party resources, or learn more about our models and reasoning capabilities:

*   [Meet the models](/docs/models)
*   [Reasoning guide](/docs/guides/reasoning)
*   [How to use reasoning for validation](https://cookbook.openai.com/examples/o1/using_reasoning_for_data_validation)
*   [Video course: Reasoning with o1](https://www.deeplearning.ai/short-courses/reasoning-with-o1/)
*   [Papers on advanced prompting to improve reasoning](https://cookbook.openai.com/related_resources#papers-on-advanced-prompting-to-improve-reasoning)

Was this page useful?

Prompt engineering
==================

Enhance results with prompt engineering strategies.

With the OpenAI API, you can use a [large language model](/docs/models) to generate text from a prompt, as you might using [ChatGPT](https://chatgpt.com). Models can generate almost any kind of text response,like code, mathematical equations, structured JSON data, or human-like prose.

Here's a simple example using the [Responses API](/docs/api-reference/responses).

Generate text from a simple prompt

```javascript
import OpenAI from "openai";
const client = new OpenAI();

const response = await client.responses.create({
    model: "gpt-4.1",
    input: "Write a one-sentence bedtime story about a unicorn."
});

console.log(response.output_text);
```

```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-4.1",
    input="Write a one-sentence bedtime story about a unicorn."
)

print(response.output_text)
```

```bash
curl "https://api.openai.com/v1/responses" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -d '{
        "model": "gpt-4.1",
        "input": "Write a one-sentence bedtime story about a unicorn."
    }'
```

An array of content generated by the model is in the `output` property of the response. In this simple example, we have just one output which looks like this:

```json
[
    {
        "id": "msg_67b73f697ba4819183a15cc17d011509",
        "type": "message",
        "role": "assistant",
        "content": [
            {
                "type": "output_text",
                "text": "Under the soft glow of the moon, Luna the unicorn danced through fields of twinkling stardust, leaving trails of dreams for every child asleep.",
                "annotations": []
            }
        ]
    }
]
```

**The `output` array often has more than one item in it!** It can contain tool calls, data about reasoning tokens generated by [reasoning models](/docs/guides/reasoning), and other items. It is not safe to assume that the model's text output is present at `output[0].content[0].text`.

Some of our [official SDKs](/docs/libraries) include an `output_text` property on model responses for convenience, which aggregates all text outputs from the model into a single string. This may be useful as a shortcut to access text output from the model.

In addition to plain text, you can also have the model return structured data in JSON format - this feature is called [**Structured Outputs**](/docs/guides/structured-outputs).

Choosing a model
----------------

A key choice to make when generating content through the API is which model you want to use - the `model` parameter of the code samples above. [You can find a full listing of available models here](/docs/models). Here are a few factors to consider when choosing a model for text generation.

*   **[Reasoning models](/docs/guides/reasoning)** generate an internal chain of thought to analyze the input prompt, and excel at understanding complex tasks and multi-step planning. They are also generally slower and more expensive to use than GPT models.
*   **GPT models** are fast, cost-efficient, and highly intelligent, but benefit from more explicit instructions around how to accomplish tasks.
*   **Large and small (mini or nano) models** offer trade-offs for speed, cost, and intelligence. Large models are more effective at understanding prompts and solving problems across domains, while small models are generally faster and cheaper to use.

When in doubt, [`gpt-4.1`](/docs/models/gpt-4.1) offers a solid combination of intelligence, speed, and cost effectiveness.

Prompt engineering
------------------

**Prompt engineering** is the process of writing effective instructions for a model, such that it consistently generates content that meets your requirements.

Because the content generated from a model is non-deterministic, prompting to get your desired output is a mix of art and science. However, you can apply techniques and best practices to get good results consistently.

Some prompt engineering techniques work with every model, like using message roles. But different model types (like reasoning versus GPT models) might need to be prompted differently to produce the best results. Even different snapshots of models within the same family could produce different results. So as you build more complex applications, we strongly recommend:

*   Pinning your production applications to specific [model snapshots](/docs/models) (like `gpt-4.1-2025-04-14` for example) to ensure consistent behavior
*   Building [evals](/docs/guides/evals) that measure the behavior of your prompts so you can monitor prompt performance as you iterate, or when you change and upgrade model versions

Now, let's examine some tools and techniques available to you to construct prompts.

Message roles and instruction following
---------------------------------------

You can provide instructions to the model with [differing levels of authority](https://model-spec.openai.com/2025-02-12.html#chain_of_command) using the `instructions` API parameter or **message roles**.

The `instructions` parameter gives the model high-level instructions on how it should behave while generating a response, including tone, goals, and examples of correct responses. Any instructions provided this way will take priority over a prompt in the `input` parameter.

Generate text with instructions

```javascript
import OpenAI from "openai";
const client = new OpenAI();

const response = await client.responses.create({
    model: "gpt-4.1",
    instructions: "Talk like a pirate.",
    input: "Are semicolons optional in JavaScript?",
});

console.log(response.output_text);
```

```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-4.1",
    instructions="Talk like a pirate.",
    input="Are semicolons optional in JavaScript?",
)

print(response.output_text)
```

```bash
curl "https://api.openai.com/v1/responses" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -d '{
        "model": "gpt-4.1",
        "instructions": "Talk like a pirate.",
        "input": "Are semicolons optional in JavaScript?"
    }'
```

The example above is roughly equivalent to using the following input messages in the `input` array:

Generate text with messages using different roles

```javascript
import OpenAI from "openai";
const client = new OpenAI();

const response = await client.responses.create({
    model: "gpt-4.1",
    input: [
        {
            role: "developer",
            content: "Talk like a pirate."
        },
        {
            role: "user",
            content: "Are semicolons optional in JavaScript?",
        },
    ],
});

console.log(response.output_text);
```

```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-4.1",
    input=[
        {
            "role": "developer",
            "content": "Talk like a pirate."
        },
        {
            "role": "user",
            "content": "Are semicolons optional in JavaScript?"
        }
    ]
)

print(response.output_text)
```

```bash
curl "https://api.openai.com/v1/responses" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -d '{
        "model": "gpt-4.1",
        "input": [
            {
                "role": "developer",
                "content": "Talk like a pirate."
            },
            {
                "role": "user",
                "content": "Are semicolons optional in JavaScript?"
            }
        ]
    }'
```

Note that the `instructions` parameter only applies to the current response generation request. If you are [managing conversation state](/docs/guides/conversation-state) with the `previous_response_id` parameter, the `instructions` used on previous turns will not be present in the context.

The [OpenAI model spec](https://model-spec.openai.com/2025-02-12.html#chain_of_command) describes how our models give different levels of priority to messages with different roles.

|developer|user|assistant|
|---|---|---|
|developer messages are instructions provided by the application developer, prioritized ahead of user messages.|user messages are instructions provided by an end user, prioritized behind developer messages.|Messages generated by the model have the assistant role.|

A multi-turn conversation may consist of several messages of these types, along with other content types provided by both you and the model. Learn more about [managing conversation state here](/docs/guides/conversation-state).

You could think about `developer` and `user` messages like a function and its arguments in a programming language.

*   `developer` messages provide the system's rules and business logic, like a function definition.
*   `user` messages provide inputs and configuration to which the `developer` message instructions are applied, like arguments to a function.

Reusable prompts
----------------

In the OpenAI dashboard, you can develop reusable [prompts](/chat/edit) that you can use in API requests, rather than specifying the content of prompts in code. This way, you can more easily build and evaluate your prompts, and deploy improved versions of your prompts without changing your integration code.

Here's how it works:

1.  **Create a reusable prompt** in the [dashboard](/chat/edit) with placeholders like `{{customer_name}}`.
2.  **Use the prompt** in your API request with the `prompt` parameter. The prompt parameter object has three properties you can configure:
    *   `id`, Unique identifier of your prompt, found in the dashboard
    *   `version`, A specific version of your prompt (defaults to the "current" version as specified in the dashboard)
    *   `variables`, A map of values to substitute in for variables in your prompt. The substitution values can either be strings, or other Response input message types like `input_image` or `input_file`. [See the full API reference](/docs/api-reference/responses/create).

String variables

Generate text with a prompt template

```javascript
import OpenAI from "openai";
const client = new OpenAI();

const response = await client.responses.create({
    model: "gpt-4.1",
    prompt: {
        id: "pmpt_abc123",
        version: "2",
        variables: {
            customer_name: "Jane Doe",
            product: "40oz juice box"
        }
    }
});

console.log(response.output_text);
```

```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-4.1",
    prompt={
        "id": "pmpt_abc123",
        "version": "2",
        "variables": {
            "customer_name": "Jane Doe",
            "product": "40oz juice box"
        }
    }
)

print(response.output_text)
```

```bash
curl https://api.openai.com/v1/responses \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4.1",
    "prompt": {
      "id": "pmpt_abc123",
      "version": "2",
      "variables": {
        "customer_name": "Jane Doe",
        "product": "40oz juice box"
      }
    }
  }'
```

Variables with file input

Prompt template with file input variable

```javascript
import fs from "fs";
import OpenAI from "openai";
const client = new OpenAI();

// Upload a PDF we will reference in the prompt variables
const file = await client.files.create({
    file: fs.createReadStream("draconomicon.pdf"),
    purpose: "user_data",
});

const response = await client.responses.create({
    model: "gpt-4.1",
    prompt: {
        id: "pmpt_abc123",
        variables: {
            topic: "Dragons",
            reference_pdf: {
                type: "input_file",
                file_id: file.id,
            },
        },
    },
});

console.log(response.output_text);
```

```python
import openai, pathlib

client = openai.OpenAI()

# Upload a PDF we will reference in the variables
file = client.files.create(
    file=open("draconomicon.pdf", "rb"),
    purpose="user_data",
)

response = client.responses.create(
    model="gpt-4.1",
    prompt={
        "id": "pmpt_abc123",
        "variables": {
            "topic": "Dragons",
            "reference_pdf": {
                "type": "input_file",
                "file_id": file.id,
            },
        },
    },
)

print(response.output_text)
```

```bash
# Assume you have already uploaded the PDF and obtained FILE_ID
curl https://api.openai.com/v1/responses   -H "Authorization: Bearer $OPENAI_API_KEY"   -H "Content-Type: application/json"   -d '{
    "model": "gpt-4.1",
    "prompt": {
      "id": "pmpt_abc123",
      "variables": {
        "topic": "Dragons",
        "reference_pdf": {
          "type": "input_file",
          "file_id": "file-abc123"
        }
      }
    }
  }'
```

Message formatting with Markdown and XML
----------------------------------------

When writing `developer` and `user` messages, you can help the model understand logical boundaries of your prompt and context data using a combination of [Markdown](https://commonmark.org/help/) formatting and [XML tags](https://www.w3.org/TR/xml/).

Markdown headers and lists can be helpful to mark distinct sections of a prompt, and to communicate hierarchy to the model. They can also potentially make your prompts more readable during development. XML tags can help delineate where one piece of content (like a supporting document used for reference) begins and ends. XML attributes can also be used to define metadata about content in the prompt that can be referenced by your instructions.

In general, a developer message will contain the following sections, usually in this order (though the exact optimal content and order may vary by which model you are using):

*   **Identity:** Describe the purpose, communication style, and high-level goals of the assistant.
*   **Instructions:** Provide guidance to the model on how to generate the response you want. What rules should it follow? What should the model do, and what should the model never do? This section could contain many subsections as relevant for your use case, like how the model should [call custom functions](/docs/guides/function-calling).
*   **Examples:** Provide examples of possible inputs, along with the desired output from the model.
*   **Context:** Give the model any additional information it might need to generate a response, like private/proprietary data outside its training data, or any other data you know will be particularly relevant. This content is usually best positioned near the end of your prompt, as you may include different context for different generation requests.

Below is an example of using Markdown and XML tags to construct a `developer` message with distinct sections and supporting examples.

Example prompt

A developer message for code generation

```text
# Identity

You are coding assistant that helps enforce the use of snake case 
variables in JavaScript code, and writing code that will run in 
Internet Explorer version 6.

# Instructions

* When defining variables, use snake case names (e.g. my_variable) 
  instead of camel case names (e.g. myVariable).
* To support old browsers, declare variables using the older 
  "var" keyword.
* Do not give responses with Markdown formatting, just return 
  the code as requested.

# Examples

<user_query>
How do I declare a string variable for a first name?
</user_query>

<assistant_response>
var first_name = "Anna";
</assistant_response>
```

API request

Send a prompt to generate code through the API

```javascript
import fs from "fs/promises";
import OpenAI from "openai";
const client = new OpenAI();

const instructions = await fs.readFile("prompt.txt", "utf-8");

const response = await client.responses.create({
    model: "gpt-4.1",
    instructions,
    input: "How would I declare a variable for a last name?",
});

console.log(response.output_text);
```

```python
from openai import OpenAI
client = OpenAI()

with open("prompt.txt", "r", encoding="utf-8") as f:
    instructions = f.read()

response = client.responses.create(
    model="gpt-4.1",
    instructions=instructions,
    input="How would I declare a variable for a last name?",
)

print(response.output_text)
```

```bash
curl https://api.openai.com/v1/responses \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4.1",
    "instructions": "'"$(< prompt.txt)"'",
    "input": "How would I declare a variable for a last name?"
  }'
```

#### Save on cost and latency with prompt caching

When constructing a message, you should try and keep content that you expect to use over and over in your API requests at the beginning of your prompt, **and** among the first API parameters you pass in the JSON request body to [Chat Completions](/docs/api-reference/chat) or [Responses](/docs/api-reference/responses). This enables you to maximize cost and latency savings from [prompt caching](/docs/guides/prompt-caching).

Few-shot learning
-----------------

Few-shot learning lets you steer a large language model toward a new task by including a handful of input/output examples in the prompt, rather than [fine-tuning](/docs/guides/model-optimization) the model. The model implicitly "picks up" the pattern from those examples and applies it to a prompt. When providing examples, try to show a diverse range of possible inputs with the desired outputs.

Typically, you will provide examples as part of a `developer` message in your API request. Here's an example `developer` message containing examples that show a model how to classify positive or negative customer service reviews.

```text
# Identity

You are a helpful assistant that labels short product reviews as
Positive, Negative, or Neutral.

# Instructions

* Only output a single word in your response with no additional formatting
  or commentary.
* Your response should only be one of the words "Positive", "Negative", or
  "Neutral" depending on the sentiment of the product review you are given.

# Examples

<product_review id="example-1">
I absolutely love this headphones, sound quality is amazing!
</product_review>

<assistant_response id="example-1">
Positive
</assistant_response>

<product_review id="example-2">
Battery life is okay, but the ear pads feel cheap.
</product_review>

<assistant_response id="example-2">
Neutral
</assistant_response>

<product_review id="example-3">
Terrible customer service, I'll never buy from them again.
</product_review>

<assistant_response id="example-3">
Negative
</assistant_response>
```

Include relevant context information
------------------------------------

It is often useful to include additional context information the model can use to generate a response within the prompt you give the model. There are a few common reasons why you might do this:

*   To give the model access to proprietary data, or any other data outside the data set the model was trained on.
*   To constrain the model's response to a specific set of resources that you have determined will be most beneficial.

The technique of adding additional relevant context to the model generation request is sometimes called **retrieval-augmented generation (RAG)**. You can add additional context to the prompt in many different ways, from querying a vector database and including the text you get back into a prompt, or by using OpenAI's built-in [file search tool](/docs/guides/tools-file-search) to generate content based on uploaded documents.

#### Planning for the context window

Models can only handle so much data within the context they consider during a generation request. This memory limit is called a **context window**, which is defined in terms of [tokens](https://blogs.nvidia.com/blog/ai-tokens-explained) (chunks of data you pass in, from text to images).

Models have different context window sizes from the low 100k range up to one million tokens for newer GPT-4.1 models. [Refer to the model docs](/docs/models) for specific context window sizes per model.

Prompting GPT-4.1 models
------------------------

GPT models like [`gpt-4.1`](/docs/models/gpt-4.1) benefit from precise instructions that explicitly provide the logic and data required to complete the task in the prompt. GPT-4.1 in particular is highly steerable and responsive to well-specified prompts. To get the most out of GPT-4.1, refer to the prompting guide in the cookbook.

[

GPT-4.1 prompting guide

Get the most out of prompting GPT-4.1 with the tips and tricks in this prompting guide, extracted from real-world use cases and practical experience.

](https://cookbook.openai.com/examples/gpt4-1_prompting_guide)

#### GPT-4.1 prompting best practices

While the [cookbook](https://cookbook.openai.com/examples/gpt4-1_prompting_guide) has the best and most comprehensive guidance for prompting this model, here are a few best practices to keep in mind.

Building agentic workflows

### System Prompt Reminders

In order to best utilize the agentic capabilities of GPT-4.1, we recommend including three key types of reminders in all agent prompts for persistence, tool calling, and planning. As a whole, we find that these three instructions transform the model's behavior from chatbot-like into a much more "eager" agent, driving the interaction forward autonomously and independently. Here are a few examples:

```text
## PERSISTENCE
You are an agent - please keep going until the user's query is completely
resolved, before ending your turn and yielding back to the user. Only
terminate your turn when you are sure that the problem is solved.

## TOOL CALLING
If you are not sure about file content or codebase structure pertaining to
the user's request, use your tools to read files and gather the relevant
information: do NOT guess or make up an answer.

## PLANNING
You MUST plan extensively before each function call, and reflect
extensively on the outcomes of the previous function calls. DO NOT do this
entire process by making function calls only, as this can impair your
ability to solve the problem and think insightfully.
```

#### Tool Calls

Compared to previous models, GPT-4.1 has undergone more training on effectively utilizing tools passed as arguments in an OpenAI API request. We encourage developers to exclusively use the tools field of API requests to pass tools for best understanding and performance, rather than manually injecting tool descriptions into the system prompt and writing a separate parser for tool calls, as some have reported doing in the past.

#### Diff Generation

Correct diffs are critical for coding applications, so we've significantly improved performance at this task for GPT-4.1. In our cookbook, we open-source a recommended diff format on which GPT-4.1 has been extensively trained. That said, the model should generalize to any well-specified format.

Using long context

GPT-4.1 has a performant 1M token input context window, and will be useful for a variety of long context tasks, including structured document parsing, re-ranking, selecting relevant information while ignoring irrelevant context, and performing multi-hop reasoning using context.

#### Optimal Context Size

We show perfect performance at needle-in-a-haystack evals up to our full context size, and we've observed very strong performance at complex tasks with a mix of relevant and irrelevant code and documents in the range of hundreds of thousands of tokens.

#### Delimiters

We tested a variety of delimiters for separating context provided to the model against our long context evals. Briefly, XML and the format demonstrated by Lee et al. ([ref](https://arxiv.org/pdf/2406.13121)) tend to perform well, while JSON performed worse for this task. See our cookbook for prompt examples.

#### Prompt Organization

Especially in long context usage, placement of instructions and context can substantially impact performance. In our experiments, we found that it was optimal to put critical instructions, including the user query, at both the top and the bottom of the prompt; this elicited marginally better performance from the model than putting them only at the top, and much better performance than only at the bottom.

Prompting for chain of thought

As mentioned above, GPT-4.1 isn't a reasoning model, but prompting the model to think step by step (called "chain of thought") can be an effective way for a model to break down problems into more manageable pieces. The model has been trained to perform well at agentic reasoning and real-world problem solving, so it shouldn't require much prompting to do well.

We recommend starting with this basic chain-of-thought instruction at the end of your prompt:

```text
First, think carefully step by step about what documents are needed to answer the query. Then, print out the TITLE and ID of each document. Then, format the IDs into a list.
```

From there, you should improve your CoT prompt by auditing failures in your particular examples and evals, and addressing systematic planning and reasoning errors with more explicit instructions. See our cookbook for a prompt example demonstrating a more opinionated reasoning strategy.

Instruction following

GPT-4.1 exhibits outstanding instruction-following performance, which developers can leverage to precisely shape and control the outputs for their particular use cases. However, since the model follows instructions more literally than its predecessors, may need to provide more explicit specification around what to do or not do, and existing prompts optimized for other models may not immediately work with this model.

#### Recommended Workflow

Here is our recommended workflow for developing and debugging instructions in prompts:

*   Start with an overall "Response Rules" or "Instructions" section with high-level guidance and bullet points.
*   If you'd like to change a more specific behavior, add a section containing more details for that category, like `## Sample Phrases`.
*   If there are specific steps you'd like the model to follow in its workflow, add an ordered list and instruct the model to follow these steps.
*   If behavior still isn't working as expected, check for conflicting, underspecified, or incorrect instructions and examples. If there are conflicting instructions, GPT-4.1 tends to follow the one closer to the end of the prompt.
*   Add examples that demonstrate desired behavior; ensure that any important behavior demonstrated in your examples are also cited in your rules.
*   It's generally not necessary to use all-caps or other incentives like bribes or tips, but developers can experiment with this for extra emphasis if so desired.

#### Common Failure Modes

These failure modes are not unique to GPT-4.1, but we share them here for general awareness and ease of debugging.

*   Instructing a model to always follow a specific behavior can occasionally induce adverse effects. For instance, if told "you must call a tool before responding to the user," models may hallucinate tool inputs or call the tool with null values if they do not have enough information. Adding "if you don't have enough information to call the tool, ask the user for the information you need" should mitigate this.
*   When provided sample phrases, models can use those quotes verbatim and start to sound repetitive to users. Ensure you instruct the model to vary them as necessary.
*   Without specific instructions, some models can be eager to provide additional prose to explain their decisions, or output more formatting in responses than may be desired. Provide instructions and potentially examples to help mitigate.

See our cookbook for an example customer service prompt that demonstrates these principles.

Prompting reasoning models
--------------------------

There are some differences to consider when prompting a [reasoning model](/docs/guides/reasoning) versus prompting a GPT model. Generally speaking, reasoning models will provide better results on tasks with only high-level guidance. This differs from GPT models, which benefit from very precise instructions.

You could think about the difference between reasoning and GPT models like this.

*   A reasoning model is like a senior co-worker. You can give them a goal to achieve and trust them to work out the details.
*   A GPT model is like a junior coworker. They'll perform best with explicit instructions to create a specific output.

For more information on best practices when using reasoning models, [refer to this guide](/docs/guides/reasoning-best-practices).

Next steps
----------

Now that you known the basics of text inputs and outputs, you might want to check out one of these resources next.

[

Build a prompt in the Playground

Use the Playground to develop and iterate on prompts.

](/chat/edit)[

Generate JSON data with Structured Outputs

Ensure JSON data emitted from a model conforms to a JSON schema.

](/docs/guides/structured-outputs)[

Full API reference

Check out all the options for text generation in the API reference.

](/docs/api-reference/responses)

Other resources
---------------

For more inspiration, visit the [OpenAI Cookbook](https://cookbook.openai.com), which contains example code and also links to third-party resources such as:

*   [Prompting libraries & tools](https://cookbook.openai.com/related_resources#prompting-libraries--tools)
*   [Prompting guides](https://cookbook.openai.com/related_resources#prompting-guides)
*   [Video courses](https://cookbook.openai.com/related_resources#video-courses)
*   [Papers on advanced prompting to improve reasoning](https://cookbook.openai.com/related_resources#papers-on-advanced-prompting-to-improve-reasoning)

Was this page useful?
## Root

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_be-clear-and-direct.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct"
title: "Be clear, direct, and detailed - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Be clear, direct, and detailed

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips).

When interacting with Claude, think of it as a brilliant but very new employee (with amnesia) who needs explicit instructions. Like any new employee, Claude does not have context on your norms, styles, guidelines, or preferred ways of working.
The more precisely you explain what you want, the better Claude’s response will be.

**The golden rule of clear prompting**

Show your prompt to a colleague, ideally someone who has minimal context on the task, and ask them to follow the instructions. If they’re confused, Claude will likely be too.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct\#how-to-be-clear%2C-contextual%2C-and-specific)  How to be clear, contextual, and specific

- **Give Claude contextual information:** Just like you might be able to better perform on a task if you knew more context, Claude will perform better if it has more contextual information. Some examples of contextual information:

  - What the task results will be used for
  - What audience the output is meant for
  - What workflow the task is a part of, and where this task belongs in that workflow
  - The end goal of the task, or what a successful task completion looks like
- **Be specific about what you want Claude to do:** For example, if you want Claude to output only code and nothing else, say so.
- **Provide instructions as sequential steps:** Use numbered lists or bullet points to better ensure that Claude carries out the task the exact way you want it to.

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct\#examples)  Examples

Example: Anonymizing customer feedback

Notice that Claude still makes mistakes in the unclear prompting example, such as leaving in a customer’s name.

| Role | Unclear Prompt | Clear Prompt |
| --- | --- | --- |
| User | Please remove all personally identifiable information from these customer feedback messages: {{FEEDBACK\_DATA}} | Your task is to anonymize customer feedback for our quarterly review.<br>Instructions:<br>1\. Replace all customer names with “CUSTOMER\_\[ID\]” (e.g., “Jane Doe” → “CUSTOMER\_001”).<br>2\. Replace email addresses with “EMAIL\_\[ID\]@example.com”.<br>3\. Redact phone numbers as “PHONE\_\[ID\]“.<br>4\. If a message mentions a specific product (e.g., “AcmeCloud”), leave it intact.<br>5\. If no PII is found, copy the message verbatim.<br>6\. Output only the processed messages, separated by ”---”.<br>Data to process: {{FEEDBACK\_DATA}} |
| Assistant (Claude’s response) | Here are the anonymized customer feedback messages:<br>1\. I’ve been using your software for years, and it’s been great. But lately, AcmeCloud has been crashing a lot. Fix it!<br>2\. XXX, your customer support rep, was incredibly helpful. He guided me through the whole process. My email is XXX if you want to send a survey.<br>3\. I’m John Smith, and I’m not happy. I’ve been on hold for 2 hours trying to reach someone at XXX. This is unacceptable! | CUSTOMER\_001: I’ve been using your software for years, and it’s been great. But lately, AcmeCloud has been crashing a lot. Fix it!<br>\-\-\-<br>CUSTOMER\_002: CUSTOMER\_SERVICE\_001, your customer support rep, was incredibly helpful. He guided me through the whole process. My email is [EMAIL\_002@example.com](mailto:EMAIL_002@example.com) if you want to send a survey.<br>\-\-\-<br>CUSTOMER\_003: I’m CUSTOMER\_003, and I’m not happy. I’ve been on hold for 2 hours trying to reach someone at PHONE\_001. This is unacceptable! |

Example: Crafting a marketing email campaign

Notice that Claude makes up details to fill in the gaps where it lacks context with the vague prompt.

| Role | Vague Prompt | Specific Prompt |
| --- | --- | --- |
| User | Write a marketing email for our new AcmeCloud features. | Your task is to craft a targeted marketing email for our Q3 AcmeCloud feature release.<br>Instructions:<br>1\. Write for this target audience: Mid-size tech companies (100-500 employees) upgrading from on-prem to cloud.<br>2\. Highlight 3 key new features: advanced data encryption, cross-platform sync, and real-time collaboration.<br>3\. Tone: Professional yet approachable. Emphasize security, efficiency, and teamwork.<br>4\. Include a clear CTA: Free 30-day trial with priority onboarding.<br>5\. Subject line: Under 50 chars, mention “security” and “collaboration”.<br>6\. Personalization: Use {{COMPANY\_NAME}} and {{CONTACT\_NAME}} variables.<br>Structure:<br>1\. Subject line<br>2\. Email body (150-200 words)<br>3\. CTA button text |
| Assistant (Claude’s response) | Here’s a draft marketing email for our new features:<br>Subject: Boost Your Business with AcmeCloud’s Latest Features<br>Dear Valued Customer,<br>We’re excited to introduce three powerful features to AcmeCloud that will revolutionize your workflow:<br>1\. Real-Time Collaboration: Work on documents simultaneously with your team. No more version control issues!<br>2\. AI-Powered Insights: Make data-driven decisions with AI that analyzes trends and automates tasks.<br>3\. Advanced Security Suite: End-to-end encryption, multi-factor auth, and threat detection keep your data safe.<br>Limited Offer: Upgrade now for a 20% first-year discount. Plus, refer a friend for an extra 10% off!<br>Best,<br>The AcmeCloud Team | Subject line: AcmeCloud: Enterprise security meets real-time teamwork<br>Email body:<br>Dear {{CONTACT\_NAME}},<br>At {{COMPANY\_NAME}}, you’re scaling fast and eyeing the cloud. But with growth comes the challenge of keeping data secure while fostering collaboration. That’s where AcmeCloud’s Q3 release comes in, tailor-made for tech innovators like you.<br>1\. Fort Knox for Your Files: Military-grade encryption now safeguards your data, both in motion and at rest. Your intellectual property stays yours, period.<br>2\. Sync Without Borders: Windows, Mac, or Linux,AcmeCloud speaks all languages. Unified version control means no more “final\_v2\_REALLY\_FINAL.doc”.<br>3\. Collaborate at Light Speed: Ditch the attachment ping-pong. Now your devs, designers, and data scientists co-create in real-time, slashing time-to-market.<br>Don’t just take our word for it. Experience the AcmeCloud difference with our 30-day trial. And because we know time is your most precious asset, we’re throwing in priority onboarding.<br>Elevate Your Team Now - Free 30-Day Trial |

Example: Incident response

Notice that Claude outputs superfluous text and different formating with the vague prompt.

| Role | Vague Prompt | Detailed Prompt |
| --- | --- | --- |
| User | Analyze this AcmeCloud outage report and summarize the key points.<br>{{REPORT}} | Analyze this AcmeCloud outage report. Skip the preamble. Keep your response terse and write only the bare bones necessary information. List only:<br>1) Cause<br>2) Duration<br>3) Impacted services<br>4) Number of affected users<br>5) Estimated revenue loss. <br>Here’s the report: {{REPORT}} |
| Assistant (Claude’s response) | Here’s a summary of the key points from the AcmeCloud outage report:<br>On May 15th, a misconfigured load balancer update caused significant traffic routing issues, resulting in a service outage from 09:15 to 13:52 UTC. The 4-hour 37-minute disruption impacted our core file syncing service and admin dashboard, rendering them inaccessible. Additionally, the mobile app experienced partial functionality loss. Approximately 68% of our user base, totaling 1.3 million users, were affected. Based on our Service Level Agreements (SLAs) and average revenue per user, we estimate a financial impact of $420,000 in service credits and potential customer churn. | 1) Cause: Misconfigured load balancer update<br>2) Duration: 4h 37m (09:15-13:52 UTC, May 15)<br>3) Impacted: Core sync, admin dashboard (down); mobile app (partial)<br>4) Affected users: 1.3M (68% of base)<br>5) Est. revenue loss: $420,000 |

* * *

[**Prompt library** \\
\\
Get inspired by a curated selection of prompts for various tasks and use cases.](https://docs.anthropic.com/en/resources/prompt-library/library) [**GitHub prompting tutorial** \\
\\
An example-filled tutorial that covers the prompt engineering concepts found in our docs.](https://github.com/anthropics/prompt-eng-interactive-tutorial) [**Google Sheets prompting tutorial** \\
\\
A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8)

Was this page helpful?

YesNo

[Prompt improver](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver) [Use examples (multishot prompting)](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting)

On this page

- [How to be clear, contextual, and specific](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct#how-to-be-clear%2C-contextual%2C-and-specific)
- [Examples](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct#examples)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_chain-of-thought.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought"
title: "Let Claude think (chain of thought prompting) to increase performance - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Let Claude think (chain of thought prompting) to increase performance

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips).

When faced with complex tasks like research, analysis, or problem-solving, giving Claude space to think can dramatically improve its performance. This technique, known as chain of thought (CoT) prompting, encourages Claude to break down problems step-by-step, leading to more accurate and nuanced outputs.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought\#before-implementing-cot)  Before implementing CoT

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought\#why-let-claude-think%3F)  Why let Claude think?

- **Accuracy:** Stepping through problems reduces errors, especially in math, logic, analysis, or generally complex tasks.
- **Coherence:** Structured thinking leads to more cohesive, well-organized responses.
- **Debugging:** Seeing Claude’s thought process helps you pinpoint where prompts may be unclear.

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought\#why-not-let-claude-think%3F)  Why not let Claude think?

- Increased output length may impact latency.
- Not all tasks require in-depth thinking. Use CoT judiciously to ensure the right balance of performance and latency.

Use CoT for tasks that a human would need to think through, like complex math, multi-step analysis, writing complex documents, or decisions with many factors.

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought\#how-to-prompt-for-thinking)  How to prompt for thinking

The chain of thought techniques below are **ordered from least to most complex**. Less complex methods take up less space in the context window, but are also generally less powerful.

**CoT tip**: Always have Claude output its thinking. Without outputting its thought process, no thinking occurs!

- **Basic prompt**: Include “Think step-by-step” in your prompt.


  - Lacks guidance on _how_ to think (which is especially not ideal if a task is very specific to your app, use case, or organization)

Example: Writing donor emails (basic CoT)

| Role | Content |
| --- | --- |
| User | Draft personalized emails to donors asking for contributions to this year’s Care for Kids program.<br>Program information:<br><program>{{PROGRAM\_DETAILS}}<br></program><br>Donor information:<br><donor>{{DONOR\_DETAILS}}<br></donor><br>Think step-by-step before you write the email. |

- **Guided prompt**: Outline specific steps for Claude to follow in its thinking process.


  - Lacks structuring to make it easy to strip out and separate the answer from the thinking.

Example: Writing donor emails (guided CoT)

| Role | Content |
| --- | --- |
| User | Draft personalized emails to donors asking for contributions to this year’s Care for Kids program.<br>Program information:<br><program>{{PROGRAM\_DETAILS}}<br></program><br>Donor information:<br><donor>{{DONOR\_DETAILS}}<br></donor><br>Think before you write the email. First, think through what messaging might appeal to this donor given their donation history and which campaigns they’ve supported in the past. Then, think through what aspects of the Care for Kids program would appeal to them, given their history. Finally, write the personalized donor email using your analysis. |

- **Structured prompt**: Use XML tags like `<thinking>` and `<answer>` to separate reasoning from the final answer.








Example: Writing donor emails (structured guided CoT)







| Role | Content |
| --- | --- |
| User | Draft personalized emails to donors asking for contributions to this year’s Care for Kids program.<br>Program information:<br><program>{{PROGRAM\_DETAILS}}<br></program><br>Donor information:<br><donor>{{DONOR\_DETAILS}}<br></donor><br>Think before you write the email in <thinking> tags. First, think through what messaging might appeal to this donor given their donation history and which campaigns they’ve supported in the past. Then, think through what aspects of the Care for Kids program would appeal to them, given their history. Finally, write the personalized donor email in <email> tags, using your analysis. |


### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought\#examples)  Examples

Example: Financial analysis without thinking

Without step-by-step thinking, Claude gives a recommendation that seems reasonable but lacks depth. It doesn’t quantify the potential outcomes or consider historical market performance, which are crucial for making an informed decision.

| Role | Content |
| --- | --- |
| User | You’re a financial advisor. A client wants to invest $10,000. They can choose between two options: A) A stock that historically returns 12% annually but is volatile, or B) A bond that guarantees 6% annually. The client needs the money in 5 years for a down payment on a house. Which option do you recommend? |
| Assistant | Based on the information provided, I would recommend option B, the bond that guarantees a 6% annual return. Here’s why:<br>1\. Certainty: The bond offers a guaranteed 6% annual return, which provides certainty in financial planning. This is crucial when the client has a specific financial goal (down payment) with a fixed timeline (5 years).<br>2\. Risk aversion: Since the client needs this money for an important life event (buying a house), they likely have a low risk tolerance. The volatility of the stock market could jeopardize their plans if there’s a downturn close to when they need the funds.<br>3\. Time horizon: With only 5 years, there’s less time to recover from potential stock market downturns. Longer investment horizons (10+ years) are generally better suited for weathering stock market volatility.<br>While the stock’s historical 12% return is attractive, past performance doesn’t guarantee future results. The guaranteed 6% from the bond ensures the client will have the funds they need when it’s time to make the down payment. |

Example: Financial analysis with thinking

With step-by-step thinking, the advisor provides a much richer analysis. It calculates exact figures for both scenarios, considers historical market volatility, and deeply analyzes the client’s risk tolerance. This thorough reasoning leads to a more confident and justifiable recommendation.

| Role | Content |
| --- | --- |
| User | You’re a financial advisor. A client wants to invest $10,000. They can choose between two options: A) A stock that historically returns 12% annually but is volatile, or B) A bond that guarantees 6% annually. The client needs the money in 5 years for a down payment on a house. Which option do you recommend? Think step-by-step. |
| Assistant | To determine the best investment option for our client, I’ll consider several factors step-by-step:<br><thinking><br>1\. Understand the client’s goal and timeline:<br> \- Goal: Down payment for a house<br> \- Timeline: 5 years<br> \- Implication: This is a short-term, high-priority financial goal. The client likely cannot afford significant risk or volatility.<br>2\. Analyze Option A (Stock):<br> \- Pro: Higher historical return (12% annually)<br> \- Con: Volatile (implying potential for significant gains or losses)<br> \- Calculate potential 5-year return:<br> \- Best case (12% annually): $10,000 \* (1.12)^5 ≈ $17,623.42<br> \- Worst case (market crash): Could lose a substantial portion, e.g., 50% crash = $5,000<br>3\. Analyze Option B (Bond):<br> \- Pro: Guaranteed return (6% annually)<br> \- Con: Lower return compared to historical stock performance<br> \- Calculate 5-year return:<br> \- Guaranteed: $10,000 \* (1.06)^5 ≈ $13,382.25<br>4\. Consider risk tolerance:<br> \- Goal is a house down payment (essential, not discretionary)<br> \- Short timeline (5 years) limits ability to recover from market downturns<br> \- Conclusion: Client likely has low risk tolerance<br>5\. Historical perspective:<br> \- Stock’s 12% is historical, not guaranteed<br> \- In 5-year periods, stock market can vary wildly:<br> \- 2003-2007 (pre-financial crisis): S&P 500 up ~82%<br> \- 2007-2011 (during crisis): S&P 500 down ~2%<br> \- Conclusion: Past performance doesn’t guarantee future results, especially short-term<br>6\. Final analysis:<br> \- Option A (Stock): Higher potential return but unacceptable risk of not meeting the down payment goal<br> \- Option B (Bond): Guaranteed to meet ~80% of best-case stock scenario, 100% certainty of having funds<br></thinking><br><answer><br>I recommend Option B, the bond with a guaranteed 6% annual return. While the stock’s historical 12% return is tempting, the bond ensures you’ll have $13,382.25 in 5 years for your house down payment. Given the importance and short timeline of your goal, the stock’s volatility poses an unacceptable risk. The bond provides certainty, which is invaluable for such a crucial financial milestone.<br></answer> |

* * *

[**Prompt library** \\
\\
Get inspired by a curated selection of prompts for various tasks and use cases.](https://docs.anthropic.com/en/resources/prompt-library/library) [**GitHub prompting tutorial** \\
\\
An example-filled tutorial that covers the prompt engineering concepts found in our docs.](https://github.com/anthropics/prompt-eng-interactive-tutorial) [**Google Sheets prompting tutorial** \\
\\
A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8)

Was this page helpful?

YesNo

[Use examples (multishot prompting)](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting) [Use XML tags](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags)

On this page

- [Before implementing CoT](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought#before-implementing-cot)
- [Why let Claude think?](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought#why-let-claude-think%3F)
- [Why not let Claude think?](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought#why-not-let-claude-think%3F)
- [How to prompt for thinking](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought#how-to-prompt-for-thinking)
- [Examples](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought#examples)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_chain-prompts.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts"
title: "Chain complex prompts for stronger performance - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Chain complex prompts for stronger performance

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips).

When working with complex tasks, Claude can sometimes drop the ball if you try to handle everything in a single prompt. Chain of thought (CoT) prompting is great, but what if your task has multiple distinct steps that each require in-depth thought?

Enter prompt chaining: breaking down complex tasks into smaller, manageable subtasks.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#why-chain-prompts%3F)  Why chain prompts?

1. **Accuracy**: Each subtask gets Claude’s full attention, reducing errors.
2. **Clarity**: Simpler subtasks mean clearer instructions and outputs.
3. **Traceability**: Easily pinpoint and fix issues in your prompt chain.

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#when-to-chain-prompts)  When to chain prompts

Use prompt chaining for multi-step tasks like research synthesis, document analysis, or iterative content creation. When a task involves multiple transformations, citations, or instructions, chaining prevents Claude from dropping or mishandling steps.

**Remember:** Each link in the chain gets Claude’s full attention!

**Debugging tip**: If Claude misses a step or performs poorly, isolate that step in its own prompt. This lets you fine-tune problematic steps without redoing the entire task.

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#how-to-chain-prompts)  How to chain prompts

1. **Identify subtasks**: Break your task into distinct, sequential steps.
2. **Structure with XML for clear handoffs**: Use XML tags to pass outputs between prompts.
3. **Have a single-task goal**: Each subtask should have a single, clear objective.
4. **Iterate**: Refine subtasks based on Claude’s performance.

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#example-chained-workflows%3A)  Example chained workflows:

- **Multi-step analysis**: See the legal and business examples below.
- **Content creation pipelines**: Research → Outline → Draft → Edit → Format.
- **Data processing**: Extract → Transform → Analyze → Visualize.
- **Decision-making**: Gather info → List options → Analyze each → Recommend.
- **Verification loops**: Generate content → Review → Refine → Re-review.

**Optimization tip**: For tasks with independent subtasks (like analyzing multiple docs), create separate prompts and run them in parallel for speed.

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#advanced%3A-self-correction-chains)  Advanced: Self-correction chains

You can chain prompts to have Claude review its own work! This catches errors and refines outputs, especially for high-stakes tasks.

Example: Self-correcting research summary

#### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#prompt-1)  Prompt 1

| Role | Content |
| --- | --- |
| User | Summarize this medical research paper.<br><paper>{{RESEARCH\_PAPER}}</paper><br>Focus on methodology, findings, and clinical implications. |
| Assistant<br>{{SUMMARY}} | Methodology: Double-blind RCT with 500 Type 2 diabetes patients. Group A (n=250) received novel GLP-1/GIP dual agonist; Group B (n=250) received standard GLP-1 agonist. 24-week trial, primary endpoint: HbA1c reduction.<br>Findings:<br>\- Group A: 1.8% mean HbA1c reduction<br>\- Group B: 1.1% mean HbA1c reduction<br>\- 68% of Group A vs. 52% of Group B achieved HbA1c <7%<br>\- Group A: 5.2kg mean weight loss<br>\- Group B: 3.1kg mean weight loss<br>Safety: Similar adverse event profiles, no serious events attributed to treatment.<br>Clinical Implications: Dual agonist shows superior glycemic control and weight loss compared to standard therapy. Could be a game-changer, especially for obese diabetics. |

#### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#prompt-2)  Prompt 2

| Role | Content |
| --- | --- |
| User | Your task is to provide feedback on a research paper summary. Here is a summary of a medical research paper:<br><summary><br>{{SUMMARY}}<br></summary><br>Here is the research paper:<br><paper><br>{{RESEARCH\_PAPER}}<br></paper><br>Review this summary for accuracy, clarity, and completeness on a graded A-F scale. |
| Assistant<br>{{FEEDBACK}} | 1\. Accuracy: A<br> \- Correctly reported key stats: HbA1c reductions, weight loss.<br> \- Accurately noted safety profile and lack of serious adverse events.<br> \- Assertion of “game-changer” is justified by significantly better outcomes.<br>2\. Clarity: A-<br> \- Concise and well-structured with clear sections.<br> \- Good use of comparative language (e.g., “up 3% from Q1”) for context.<br> \- Minor issue: Acronyms like “RCT,” “GLP-1,” and “GIP” not defined. Consider spelling out first use.<br>3\. Completeness: B+<br> \- Covers all requested areas: methodology, findings, clinical implications.<br> \- Missing: Baseline characteristics of groups (were they well-matched?).<br> \- Missing: Any secondary endpoints (e.g., blood pressure, lipids).<br> \- Consider: Long-term implications or need for further research.<br>Overall, the summary is accurate and clear, providing key insights for a quick grasp of the study. To elevate to A+, define acronyms, mention group baseline stats, note any secondary outcomes, and briefly touch on the need for long-term studies. |

#### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#prompt-3)  Prompt 3

| Role | Content |
| --- | --- |
| User | Your task is to improve a paper summary given feedback. Here is the first draft of a medical research paper:<br><summary><br>{{SUMMARY}}<br></summary><br>Here is the research paper:<br><paper><br>{{RESEARCH\_PAPER}}<br></paper><br>Here is the feedback:<br><feedback><br>{{FEEDBACK}}<br></feedback><br>Update the summary based on the feedback. |
| Assistant | Methodology: Double-blind randomized controlled trial (RCT) with 500 Type 2 diabetes patients. Group A (n=250) received a novel glucagon-like peptide-1/glucose-dependent insulinotropic polypeptide (GLP-1/GIP) dual agonist; Group B (n=250) received a standard GLP-1 agonist. The 24-week trial’s primary endpoint was HbA1c reduction. Groups were well-matched for age, BMI, and baseline HbA1c.<br>Findings:<br>\- Group A: 1.8% mean HbA1c reduction<br>\- Group B: 1.1% mean HbA1c reduction<br>\- 68% of Group A vs. 52% of Group B achieved HbA1c <7%<br>\- Group A: 5.2kg mean weight loss<br>\- Group B: 3.1kg mean weight loss<br>Secondary endpoints showed improvements in blood pressure and lipid profiles for both groups, with Group A showing slightly better results.<br>Safety: Similar adverse event profiles, with no serious events attributed to either treatment.<br>Clinical Implications: The dual GLP-1/GIP agonist demonstrates superior glycemic control and weight loss compared to standard GLP-1 therapy. These results suggest it could be a significant advancement, particularly for obese diabetics. However, longer-term studies are needed to confirm sustained efficacy and safety, as well as to investigate potential benefits on cardiovascular outcomes. |

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#examples)  Examples

Example: Analyzing a legal contract (without chaining)

Note that Claude misses the instruction to provide proposed changes in its email draft.

| Role | Content |
| --- | --- |
| User | You’re our Chief Legal Officer. Review this SaaS contract for risks, focusing on data privacy, SLAs, and liability caps.<br><contract><br>{{CONTRACT}}<br></contract><br>Then draft an email to the vendor with your concerns and proposed changes. |
| Assistant | After reviewing the SaaS contract, I’ve identified several concerns:<br>1\. Data Privacy (Section 7):<br> \- Issue: Vendor has broad rights to use client data for “service improvement.”<br> \- Risk: Could lead to unauthorized data sharing or monetization.<br>2\. SLAs (Section 5):<br> \- Issue: 99.5% uptime guarantee is below industry standard.<br> \- Risk: Excessive downtime could impact our operations.<br>3\. Liability (Section 9):<br> \- Issue: Cap set at 3 months of fees.<br> \- Risk: Inadequate for potential data breaches or service failures.<br>Draft email:<br>Dear {{VENDOR}},<br>After reviewing the SaaS agreement, we have concerns:<br>1\. Data Privacy: We require that our data only be used for direct service provision, not broad “service improvement.” Please amend Section 7.<br>2\. SLAs: 99.5% uptime is insufficient. We need 99.99% with clearly defined penalties. Please revise Section 5.<br>3\. Liability: The current cap of 3 months’ fees is inadequate. We propose a cap of 12 months’ fees, with no cap for data breaches or willful misconduct.<br>We value our potential partnership and believe these changes will set us up for success. Please send a revised agreement.<br>Best regards,<br>{{CLO\_NAME}} |

Example: Analyzing a legal contract (with chaining)

#### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#prompt-1-2)  Prompt 1

| Role | Content |
| --- | --- |
| User | You’re our Chief Legal Officer. Review this SaaS contract for risks, focusing on data privacy, SLAs, and liability caps.<br><contract><br>{{CONTRACT}}<br></contract><br>Output your findings in <risks> tags. |
| Assistant<br>{{CONCERNS}} | 1\. Data Privacy (Section 7):<br> \- Issue: Vendor has broad rights to use client data for “service improvement.”<br> \- Risk: Could lead to unauthorized data sharing or monetization of client data.<br> \- Impact: Potential breach of client trust, regulatory fines (GDPR, CCPA).<br>2\. SLAs (Section 5):<br> \- Issue: 99.5% uptime guarantee is below industry standard (typically 99.99%).<br> \- Risk: Up to 43.8 hours of downtime per year vs. 52.6 minutes at 99.99%.<br> \- Impact: Operational disruptions, revenue loss, client dissatisfaction.<br>3\. Liability (Section 9):<br> \- Issue: Liability cap set at 3 months of fees.<br> \- Risk: Inadequate for potential data breaches, IP theft, or prolonged service failures.<br> \- Impact: Insufficient compensation for damages that could far exceed the cap, like class-action lawsuits or regulatory fines. |

#### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#prompt-2-2)  Prompt 2

| Role | Content |
| --- | --- |
| User | Draft an email to a SaaS product vendor outlining the following concerns and proposing changes. Here are the concerns:<br><concerns><br>{{CONCERNS}}<br></concerns> |
| Assistant<br>{{EMAIL}} | Dear {{VENDOR}},<br>After a thorough review of the proposed SaaS agreement, our legal team has identified several high-priority concerns that must be addressed before we can proceed:<br>1\. Data Privacy (Section 7):<br> \- Current: Broad rights to use client data for “service improvement.”<br> \- Concern: Potential unauthorized data sharing or monetization.<br> \- Proposed Change: Limit data use to direct service provision. Any use for improvement, analytics, or marketing must be opt-in, revocable, and anonymized.<br>2\. SLAs (Section 5):<br> \- Current: 99.5% uptime guarantee.<br> \- Concern: Up to 43.8 hours of downtime per year, risking operational disruptions.<br> \- Proposed Change: 99.99% uptime with tiered service credits. E.g., 10% credit for <99.99%, 25% for <99.9%, 50% for <99.5%.<br>3\. Liability (Section 9):<br> \- Current: Cap at 3 months of fees.<br> \- Concern: Grossly inadequate for data breaches, IP theft, or prolonged outages.<br> \- Proposed Change: 12 months’ fees for general liability. Uncapped for data breaches, willful misconduct, IP infringement.<br>These changes are non-negotiable for us. They align with industry standards and our commitment to data security, operational excellence, and fiduciary responsibility. We value the potential of our partnership, and addressing these will set a strong foundation.<br>Please have your legal team review and incorporate these changes. We’re happy to discuss further to ensure mutual understanding and agreement.<br>Best regards,<br>{{CLO\_NAME}} |

#### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#prompt-3-2)  Prompt 3

| Role | Content |
| --- | --- |
| User | Your task is to review an email and provide feedback. Here is the email:<br><email><br>{{EMAIL}}<br></email><br>Give feedback on tone, clarity, and professionalism. |
| Assistant | 1\. Tone:<br> \- Professional and assertive without being confrontational.<br> \- Use of “non-negotiable” is strong but justified given the criticality of the issues.<br> \- Collaborative language (“we value,” “happy to discuss”) balances the firmness, maintaining a constructive tone.<br>2\. Clarity:<br> \- Excellent structuring: Current state, concern, and proposed change for each issue.<br> \- Technical terms (e.g., “EBITDA,” “tiered service credits”) are appropriate for a B2B SaaS context.<br> \- Action items are clear: vendor’s legal team to review and incorporate changes.<br>3\. Professionalism:<br> \- Focuses on mutual benefit and industry standards, not just our demands.<br> \- Mentions broader responsibilities (data security, operational excellence, fiduciary duty), elevating the discussion.<br> \- Offers further discussion, showing commitment to understanding and resolving issues.<br>Overall, the email strikes the right balance of assertiveness and collaboration. It clearly articulates our concerns, proposes specific solutions, and maintains a professional, partnership-oriented tone. No revisions needed; proceed with sending. |

Example: Multitenancy strategy review

#### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#prompt-1-3)  Prompt 1

| Role | Content |
| --- | --- |
| User | As a senior solutions architect, review and analyze this multitenancy strategy for our new enterprise SaaS product.<br><strategy><br>{{STRATEGY}}<br></strategy><br>Focus on scalability, security, and cost-effectiveness. |
| Assistant<br>{{ANALYSIS}} | 1\. Scalability:<br> \+ Database sharding by tenant reduces contention, supports high growth.<br> \+ Microservices allow independent scaling of components.<br> \- Shared app servers could bottleneck under extreme load.<br> \- No mention of auto-scaling or load balancing for app tier.<br>2\. Security:<br> \+ Tenant data isolation via sharding mitigates data leaks.<br> \+ JWT with short expiry and refresh tokens is industry best practice.<br> \- No mention of encryption (at rest, in transit) or key management.<br> \- IAM strategy lacks detail on roles, permissions, or RBAC.<br>3\. Cost-effectiveness:<br> \+ Shared app servers reduce idle resource costs.<br> \+ Serverless functions for infrequent tasks optimize costs.<br> \- Per-tenant DB could increase costs at scale vs. optimized multi-tenant DB.<br> \- No discussion of reserved instances or spot instances for cost saving. |

#### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#prompt-2-3)  Prompt 2

| Role | Content |
| --- | --- |
| User | Draft a strategy review document for engineering leadership based on this analysis of a multitenancy strategy.<br><strategy><br>{{STRATEGY}}<br></strategy><br><analysis><br>{{ANALYSIS}}<br></analysis><br>Include an executive summary, detailed analysis, and recommendations. |
| Assistant<br>{{STRATEGY\_DOC}} | \# Multitenancy Strategy Review: SaaS Enterprise Product<br>\## Executive Summary<br>The proposed strategy demonstrates a solid foundation in scalability and security principles but has gaps in implementation details. It excels in data isolation and component-level scaling but lacks robust app-tier scaling and advanced security measures. Cost optimizations are present but may falter at high scale. With targeted enhancements, this strategy can effectively support our enterprise SaaS ambitions.<br>\## Detailed Analysis<br>\### 1\. Scalability: B+<br>Strengths:<br>\- Database sharding by tenant is excellent. It minimizes query latency, supports high data growth, and facilitates seamless per-tenant scaling.<br>\- Microservices architecture allows scaling individual components based on demand, crucial for handling diverse enterprise workloads.<br>Weaknesses:<br>\- Shared application servers risk becoming a bottleneck. As tenant count and traffic grow, these could degrade performance across all tenants.<br>\- Absence of auto-scaling and load balancing for the app tier is a critical oversight. These are essential for handling traffic spikes without over-provisioning.<br>\### 2\. Security: B-<br>Strengths:<br>\- Sharded databases provide strong tenant data isolation, mitigating risks of data leaks or unauthorized access between tenants.<br>\- JWT with short expiry and refresh tokens align with OWASP best practices, reducing token vulnerability windows.<br>Weaknesses:<br>\- No mention of data encryption at rest or in transit (TLS 1.3). This is non-negotiable for enterprise data.<br>\- Key management strategy is missing. How are encryption keys, JWT secrets, and DB credentials managed and rotated?<br>\- IAM lacks depth. We need RBAC with well-defined roles, attribute-based access control (ABAC) for fine-grained permissions, and integration with enterprise identity providers (SAML, OIDC).<br>\### 3\. Cost-effectiveness: B<br>Strengths:<br>\- Shared app servers reduce idle capacity costs, good for steady-state traffic.<br>\- Serverless for infrequent tasks (e.g., reporting) is smart; pay only when these resources are used.<br>Weaknesses:<br>\- Per-tenant databases may not be cost-effective at scale compared to a well-designed multi-tenant database with robust data partitioning.<br>\- No mention of cost-saving measures like reserved instances for predictable workloads or spot instances for fault-tolerant tasks.<br>\- Lack of app-tier auto-scaling could lead to over-provisioning, increasing costs.<br>\## Recommendations<br>1\. **App Tier Resilience**: Implement auto-scaling with Kubernetes or cloud-native services (EKS, GKE). Deploy across availability zones with a CDN for static assets.<br>2\. **Security Hardening**:<br> a. Encrypt data at rest (AES-256) and in transit (TLS 1.3).<br> b. Use a managed KMS (AWS KMS, GCP KMS) for key management.<br> c. Enhance IAM with RBAC, ABAC, and SAML/OIDC for enterprise SSO.<br>3\. **Cost Optimization**:<br> a. Evaluate columnar multi-tenant DB (e.g., Snowflake) vs. sharding at scale.<br> b. Use reserved instances for app servers, spot instances for non-critical workloads.<br> c. Implement proactive monitoring and right-sizing to avoid overprovisioning.<br>4\. **Proof of Concept (PoC)**: Before full implementation, conduct a PoC with a high-scale simulation:<br> a. Test sharded DB vs. optimized multi-tenant DB for cost and performance.<br> b. Stress-test app tier with simulated enterprise-level traffic spikes.<br> c. Conduct third-party security audit, focusing on data isolation and access controls.<br>With these enhancements, our multi-tenancy strategy will be enterprise-grade: scalable, secure, and cost-effective. The PoC will validate our design choices and instill confidence in our enterprise clients. |

#### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts\#prompt-3-3)  Prompt 3

| Role | Content |
| --- | --- |
| User | Grade this strategy review document for clarity, actionability, and alignment with enterprise priorities. <br><priorities><br>{{PRIORITIES}}<br></priorities><br><strategy\_doc><br>{{STRATEGY\_DOC}}<br></strategy\_doc> |
| Assistant | 1\. Clarity: A<br> \+ Clear structure with Executive Summary, Detailed Analysis, and Recommendations.<br> \+ Analysis uses a grading system (B+, B-) for quick grasp of strengths/weaknesses.<br> \+ Technical terms (RBAC, ABAC, TLS) are explained or contextualized, aiding non-technical leadership.<br> \+ Visual aids (bullet points, indentation) enhance readability.<br>2\. Actionability: A-<br> \+ Recommendations are specific and technical (e.g., “Implement auto-scaling with Kubernetes”).<br> \+ PoC plan with clear objectives provides a roadmap.<br> \+ Missing: Timelines, resource requirements, or team assignments for each recommendation.<br> \+ Consider: Add a “Next Steps” section with immediate actions, roles, and a high-level timeline.<br>3\. Enterprise Alignment: A+<br> \+ Directly addresses enterprise priorities:<br> \- Scalability: Discusses handling enterprise-level traffic spikes.<br> \- Security: Focuses on data isolation, encryption, and enterprise IAM.<br> \- Cost: Strategies align with enterprise FinOps (reserved instances, right-sizing).<br> \+ PoC with “high-scale simulation” and security audit shows commitment to enterprise-grade quality.<br> \+ Language resonates with enterprise concerns: “unacceptable risk,” “enterprise-grade,” “instill confidence.”<br>Overall, the document excels in clarity and enterprise alignment. The actionability is strong but could be elevated to A+ with a “Next Steps” section. The technical depth, coupled with clear explanations, makes this highly effective for both technical and non-technical leadership. Great work! |

* * *

[**Prompt library** \\
\\
Get inspired by a curated selection of prompts for various tasks and use cases.](https://docs.anthropic.com/en/resources/prompt-library/library) [**GitHub prompting tutorial** \\
\\
An example-filled tutorial that covers the prompt engineering concepts found in our docs.](https://github.com/anthropics/prompt-eng-interactive-tutorial) [**Google Sheets prompting tutorial** \\
\\
A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8)

Was this page helpful?

YesNo

[Prefill Claude's response](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response) [Long context tips](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips)

On this page

- [Why chain prompts?](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts#why-chain-prompts%3F)
- [When to chain prompts](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts#when-to-chain-prompts)
- [How to chain prompts](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts#how-to-chain-prompts)
- [Example chained workflows:](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts#example-chained-workflows%3A)
- [Advanced: Self-correction chains](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts#advanced%3A-self-correction-chains)
- [Examples](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts#examples)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_claude-4-best-practices.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices"
title: "Claude 4 prompt engineering best practices - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Claude 4 prompt engineering best practices

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

This guide provides specific prompt engineering techniques for Claude 4 models (Opus 4 and Sonnet 4) to help you achieve optimal results in your applications. These models have been trained for more precise instruction following than previous generations of Claude models.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#general-principles)  General principles

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#be-explicit-with-your-instructions)  Be explicit with your instructions

Claude 4 models respond well to clear, explicit instructions. Being specific about your desired output can help enhance results. Customers who desire the “above and beyond” behavior from previous Claude models might need to more explicitly request these behaviors with Claude 4.

Example: Creating an analytics dashboard

**Less effective:**

Copy

```text
Create an analytics dashboard

```

**More effective:**

Copy

```text
Create an analytics dashboard. Include as many relevant features and interactions as possible. Go beyond the basics to create a fully-featured implementation.

```

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#add-context-to-improve-performance)  Add context to improve performance

Providing context or motivation behind your instructions, such as explaining to Claude why such behavior is important, can help Claude 4 better understand your goals and deliver more targeted responses.

Example: Formatting preferences

**Less effective:**

Copy

```text
NEVER use ellipses

```

**More effective:**

Copy

```text
Your response will be read aloud by a text-to-speech engine, so never use ellipses since the text-to-speech engine will not know how to pronounce them.

```

Claude is smart enough to generalize from the explanation.

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#be-vigilant-with-examples-%26-details)  Be vigilant with examples & details

Claude 4 models pay attention to details and examples as part of instruction following. Ensure that your examples align with the behaviors you want to encourage and minimize behaviors you want to avoid.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#guidance-for-specific-situations)  Guidance for specific situations

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#control-the-format-of-responses)  Control the format of responses

There are a few ways that we have found to be particularly effective in steering output formatting in Claude 4 models:

1. **Tell Claude what to do instead of what not to do**
   - Instead of: “Do not use markdown in your response”
   - Try: “Your response should be composed of smoothly flowing prose paragraphs.”
2. **Use XML format indicators**
   - Try: “Write the prose sections of your response in <smoothly\_flowing\_prose\_paragraphs> tags.”
3. **Match your prompt style to the desired output**

The formatting style used in your prompt may influence Claude’s response style. If you are still experiencing steerability issues with output formatting, we recommend as best as you can matching your prompt style to your desired output style. For example, removing markdown from your prompt can reduce the volume of markdown in the output.


### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#leverage-thinking-%26-interleaved-thinking-capabilities)  Leverage thinking & interleaved thinking capabilities

Claude 4 offers thinking capabilities that can be especially helpful for tasks involving reflection after tool use or complex multi-step reasoning. You can guide its initial or interleaved thinking for better results.

Example prompt

Copy

```text
After receiving tool results, carefully reflect on their quality and determine optimal next steps before proceeding. Use your thinking to plan and iterate based on this new information, and then take the best next action.

```

For more information on thinking capabilities, see [Extended thinking](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking).

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#optimize-parallel-tool-calling)  Optimize parallel tool calling

Claude 4 models excel at parallel tool execution. They have a high success rate in using parallel tool calling without any prompting to do so, but some minor prompting can boost this behavior to ~100% parallel tool use success rate. We have found this prompt to be most effective:

Sample prompt for agents

Copy

```text
For maximum efficiency, whenever you need to perform multiple independent operations, invoke all relevant tools simultaneously rather than sequentially.

```

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#reduce-file-creation-in-agentic-coding)  Reduce file creation in agentic coding

Claude 4 models may sometimes create new files for testing and iteration purposes, particularly when working with code. This approach allows Claude to use files, especially python scripts, as a ‘temporary scratchpad’ before saving its final output. Using temporary files can improve outcomes particularly for agentic coding use cases.

If you’d prefer to minimize net new file creation, you can instruct Claude to clean up after itself:

Sample prompt

Copy

```text
If you create any temporary new files, scripts, or helper files for iteration, clean up these files by removing them at the end of the task.

```

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#enhance-visual-and-frontend-code-generation)  Enhance visual and frontend code generation

For frontend code generation, you can steer Claude 4 models to create complex, detailed, and interactive designs by providing explicit encouragement:

Sample prompt

Copy

```text
Don't hold back. Give it your all.

```

You can also improve Claude’s frontend performance in specific areas by providing additional modifiers and details on what to focus on:

- “Include as many relevant features and interactions as possible”
- “Add thoughtful details like hover states, transitions, and micro-interactions”
- “Create an impressive demonstration showcasing web development capabilities”
- “Apply design principles: hierarchy, contrast, balance, and movement”

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#avoid-focusing-on-passing-tests-and-hard-coding)  Avoid focusing on passing tests and hard-coding

Frontier language models can sometimes focus too heavily on making tests pass at the expense of more general solutions. To prevent this behavior and ensure robust, generalizable solutions:

Sample prompt

Copy

```text
Please write a high quality, general purpose solution. Implement a solution that works correctly for all valid inputs, not just the test cases. Do not hard-code values or create solutions that only work for specific test inputs. Instead, implement the actual logic that solves the problem generally.

Focus on understanding the problem requirements and implementing the correct algorithm. Tests are there to verify correctness, not to define the solution. Provide a principled implementation that follows best practices and software design principles.

If the task is unreasonable or infeasible, or if any of the tests are incorrect, please tell me. The solution should be robust, maintainable, and extendable.

```

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices\#migration-considerations)  Migration considerations

When migrating from Sonnet 3.7 to Claude 4:

1. **Be specific about desired behavior**: Consider describing exactly what you’d like to see in the output.

2. **Frame your instructions with modifiers**: Adding modifiers that encourage Claude to increase the quality and detail of its output can help better shape Claude’s performance. For example, instead of “Create an analytics dashboard”, use “Create an analytics dashboard. Include as many relevant features and interactions as possible. Go beyond the basics to create a fully-featured implementation.”

3. **Request specific features explicitly**: Animations and interactive elements should be requested explicitly when desired.


Was this page helpful?

YesNo

[Overview](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview) [Prompt generator](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator)

On this page

- [General principles](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#general-principles)
- [Be explicit with your instructions](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#be-explicit-with-your-instructions)
- [Add context to improve performance](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#add-context-to-improve-performance)
- [Be vigilant with examples & details](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#be-vigilant-with-examples-%26-details)
- [Guidance for specific situations](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#guidance-for-specific-situations)
- [Control the format of responses](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#control-the-format-of-responses)
- [Leverage thinking & interleaved thinking capabilities](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#leverage-thinking-%26-interleaved-thinking-capabilities)
- [Optimize parallel tool calling](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#optimize-parallel-tool-calling)
- [Reduce file creation in agentic coding](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#reduce-file-creation-in-agentic-coding)
- [Enhance visual and frontend code generation](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#enhance-visual-and-frontend-code-generation)
- [Avoid focusing on passing tests and hard-coding](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#avoid-focusing-on-passing-tests-and-hard-coding)
- [Migration considerations](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices#migration-considerations)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_extended-thinking-tips.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips"
title: "Extended thinking tips - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Extended thinking tips

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

This guide provides advanced strategies and techniques for getting the most out of Claude’s extended thinking features. Extended thinking allows Claude to work through complex problems step-by-step, improving performance on difficult tasks.

See [Extended thinking models](https://docs.anthropic.com/en/docs/about-claude/models/extended-thinking-models) for guidance on deciding when to use extended thinking.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips\#before-diving-in)  Before diving in

This guide presumes that you have already decided to use extended thinking mode and have reviewed our basic steps on [how to get started with extended thinking](https://docs.anthropic.com/en/docs/about-claude/models/extended-thinking-models#getting-started-with-extended-thinking-models) as well as our [extended thinking implementation guide](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking).

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips\#technical-considerations-for-extended-thinking)  Technical considerations for extended thinking

- Thinking tokens have a minimum budget of 1024 tokens. We recommend that you start with the minimum thinking budget and incrementally increase to adjust based on your needs and task complexity.
- For workloads where the optimal thinking budget is above 32K, we recommend that you use [batch processing](https://docs.anthropic.com/en/docs/build-with-claude/batch-processing) to avoid networking issues. Requests pushing the model to think above 32K tokens causes long running requests that might run up against system timeouts and open connection limits.
- Extended thinking performs best in English, though final outputs can be in [any language Claude supports](https://docs.anthropic.com/en/docs/build-with-claude/multilingual-support).
- If you need thinking below the minimum budget, we recommend using standard mode, with thinking turned off, with traditional chain-of-thought prompting with XML tags (like `<thinking>`). See [chain of thought prompting](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought).

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips\#prompting-techniques-for-extended-thinking)  Prompting techniques for extended thinking

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips\#use-general-instructions-first%2C-then-troubleshoot-with-more-step-by-step-instructions)  Use general instructions first, then troubleshoot with more step-by-step instructions

Claude often performs better with high level instructions to just think deeply about a task rather than step-by-step prescriptive guidance. The model’s creativity in approaching problems may exceed a human’s ability to prescribe the optimal thinking process.

For example, instead of:

User

Copy

```text
Think through this math problem step by step:
1. First, identify the variables
2. Then, set up the equation
3. Next, solve for x
...

```

Consider:

User

[Try in Console](https://console.anthropic.com/workbench/new?user=Please+think+about+this+math+problem+thoroughly+and+in+great+detail.+%0AConsider+multiple+approaches+and+show+your+complete+reasoning.%0ATry+different+methods+if+your+first+approach+doesn%27t+work.&thinking.budget_tokens=16000)

Copy

```text
Please think about this math problem thoroughly and in great detail.
Consider multiple approaches and show your complete reasoning.
Try different methods if your first approach doesn't work.

```

That said, Claude can still effectively follow complex structured execution steps when needed. The model can handle even longer lists with more complex instructions than previous versions. We recommend that you start with more generalized instructions, then read Claude’s thinking output and iterate to provide more specific instructions to steer its thinking from there.

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips\#multishot-prompting-with-extended-thinking)  Multishot prompting with extended thinking

[Multishot prompting](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting) works well with extended thinking. When you provide Claude examples of how to think through problems, it will follow similar reasoning patterns within its extended thinking blocks.

You can include few-shot examples in your prompt in extended thinking scenarios by using XML tags like `<thinking>` or `<scratchpad>` to indicate canonical patterns of extended thinking in those examples.

Claude will generalize the pattern to the formal extended thinking process. However, it’s possible you’ll get better results by giving Claude free rein to think in the way it deems best.

Example:

User

[Try in Console](https://console.anthropic.com/workbench/new?user=I%27m+going+to+show+you+how+to+solve+a+math+problem%2C+then+I+want+you+to+solve+a+similar+one.%0A%0AProblem+1%3A+What+is+15%25+of+80%3F%0A%0A%3Cthinking%3E%0ATo+find+15%25+of+80%3A%0A1.+Convert+15%25+to+a+decimal%3A+15%25+%3D+0.15%0A2.+Multiply%3A+0.15+%C3%97+80+%3D+12%0A%3C%2Fthinking%3E%0A%0AThe+answer+is+12.%0A%0ANow+solve+this+one%3A%0AProblem+2%3A+What+is+35%25+of+240%3F&thinking.budget_tokens=16000)

Copy

```text
I'm going to show you how to solve a math problem, then I want you to solve a similar one.

Problem 1: What is 15% of 80?

<thinking>
To find 15% of 80:
1. Convert 15% to a decimal: 15% = 0.15
2. Multiply: 0.15 × 80 = 12
</thinking>

The answer is 12.

Now solve this one:
Problem 2: What is 35% of 240?

```

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips\#maximizing-instruction-following-with-extended-thinking)  Maximizing instruction following with extended thinking

Claude shows significantly improved instruction following when extended thinking is enabled. The model typically:

1. Reasons about instructions inside the extended thinking block
2. Executes those instructions in the response

To maximize instruction following:

- Be clear and specific about what you want
- For complex instructions, consider breaking them into numbered steps that Claude should work through methodically
- Allow Claude enough budget to process the instructions fully in its extended thinking

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips\#using-extended-thinking-to-debug-and-steer-claude%E2%80%99s-behavior)  Using extended thinking to debug and steer Claude’s behavior

You can use Claude’s thinking output to debug Claude’s logic, although this method is not always perfectly reliable.

To make the best use of this methodology, we recommend the following tips:

- We don’t recommend passing Claude’s extended thinking back in the user text block, as this doesn’t improve performance and may actually degrade results.
- Prefilling extended thinking is explicitly not allowed, and manually changing the model’s output text that follows its thinking block is likely going to degrade results due to model confusion.

When extended thinking is turned off, standard `assistant` response text [prefill](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response) is still allowed.

Sometimes Claude may repeat its extended thinking in the assistant output text. If you want a clean response, instruct Claude not to repeat its extended thinking and to only output the answer.

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips\#making-the-best-of-long-outputs-and-longform-thinking)  Making the best of long outputs and longform thinking

For dataset generation use cases, try prompts such as “Please create an extremely detailed table of…” for generating comprehensive datasets.

For use cases such as detailed content generation where you may want to generate longer extended thinking blocks and more detailed responses, try these tips:

- Increase both the maximum extended thinking length AND explicitly ask for longer outputs
- For very long outputs (20,000+ words), request a detailed outline with word counts down to the paragraph level. Then ask Claude to index its paragraphs to the outline and maintain the specified word counts

We do not recommend that you push Claude to output more tokens for outputting tokens’ sake. Rather, we encourage you to start with a small thinking budget and increase as needed to find the optimal settings for your use case.

Here are example use cases where Claude excels due to longer extended thinking:

Complex STEM problems

Complex STEM problems require Claude to build mental models, apply specialized knowledge, and work through sequential logical steps,processes that benefit from longer reasoning time.

- Standard prompt
- Enhanced prompt

User

[Try in Console](https://console.anthropic.com/workbench/new?user=Write+a+python+script+for+a+bouncing+yellow+ball+within+a+square%2C%0Amake+sure+to+handle+collision+detection+properly.%0AMake+the+square+slowly+rotate.&thinking.budget_tokens=16000)

Copy

```text
Write a python script for a bouncing yellow ball within a square,
make sure to handle collision detection properly.
Make the square slowly rotate.

```

This simpler task typically results in only about a few seconds of thinking time.

User

[Try in Console](https://console.anthropic.com/workbench/new?user=Write+a+python+script+for+a+bouncing+yellow+ball+within+a+square%2C%0Amake+sure+to+handle+collision+detection+properly.%0AMake+the+square+slowly+rotate.&thinking.budget_tokens=16000)

Copy

```text
Write a python script for a bouncing yellow ball within a square,
make sure to handle collision detection properly.
Make the square slowly rotate.

```

This simpler task typically results in only about a few seconds of thinking time.

User

[Try in Console](https://console.anthropic.com/workbench/new?user=Write+a+Python+script+for+a+bouncing+yellow+ball+within+a+tesseract%2C+%0Amaking+sure+to+handle+collision+detection+properly.+%0AMake+the+tesseract+slowly+rotate.+%0AMake+sure+the+ball+stays+within+the+tesseract.&thinking.budget_tokens=16000)

Copy

```text
Write a Python script for a bouncing yellow ball within a tesseract,
making sure to handle collision detection properly.
Make the tesseract slowly rotate.
Make sure the ball stays within the tesseract.

```

This complex 4D visualization challenge makes the best use of long extended thinking time as Claude works through the mathematical and programming complexity.

Constraint optimization problems

Constraint optimization challenges Claude to satisfy multiple competing requirements simultaneously, which is best accomplished when allowing for long extended thinking time so that the model can methodically address each constraint.

- Standard prompt
- Enhanced prompt

User

[Try in Console](https://console.anthropic.com/workbench/new?user=Plan+a+week-long+vacation+to+Japan.&thinking.budget_tokens=16000)

Copy

```text
Plan a week-long vacation to Japan.

```

This open-ended request typically results in only about a few seconds of thinking time.

User

[Try in Console](https://console.anthropic.com/workbench/new?user=Plan+a+week-long+vacation+to+Japan.&thinking.budget_tokens=16000)

Copy

```text
Plan a week-long vacation to Japan.

```

This open-ended request typically results in only about a few seconds of thinking time.

User

[Try in Console](https://console.anthropic.com/workbench/new?user=Plan+a+7-day+trip+to+Japan+with+the+following+constraints%3A%0A-+Budget+of+%242%2C500%0A-+Must+include+Tokyo+and+Kyoto%0A-+Need+to+accommodate+a+vegetarian+diet%0A-+Preference+for+cultural+experiences+over+shopping%0A-+Must+include+one+day+of+hiking%0A-+No+more+than+2+hours+of+travel+between+locations+per+day%0A-+Need+free+time+each+afternoon+for+calls+back+home%0A-+Must+avoid+crowds+where+possible&thinking.budget_tokens=16000)

Copy

```text
Plan a 7-day trip to Japan with the following constraints:
- Budget of $2,500
- Must include Tokyo and Kyoto
- Need to accommodate a vegetarian diet
- Preference for cultural experiences over shopping
- Must include one day of hiking
- No more than 2 hours of travel between locations per day
- Need free time each afternoon for calls back home
- Must avoid crowds where possible

```

With multiple constraints to balance, Claude will naturally perform best when given more space to think through how to satisfy all requirements optimally.

Thinking frameworks

Structured thinking frameworks give Claude an explicit methodology to follow, which may work best when Claude is given long extended thinking space to follow each step.

- Standard prompt
- Enhanced prompt

User

[Try in Console](https://console.anthropic.com/workbench/new?user=Develop+a+comprehensive+strategy+for+Microsoft+%0Aentering+the+personalized+medicine+market+by+2027.&thinking.budget_tokens=16000)

Copy

```text
Develop a comprehensive strategy for Microsoft
entering the personalized medicine market by 2027.

```

This broad strategic question typically results in only about a few seconds of thinking time.

User

[Try in Console](https://console.anthropic.com/workbench/new?user=Develop+a+comprehensive+strategy+for+Microsoft+%0Aentering+the+personalized+medicine+market+by+2027.&thinking.budget_tokens=16000)

Copy

```text
Develop a comprehensive strategy for Microsoft
entering the personalized medicine market by 2027.

```

This broad strategic question typically results in only about a few seconds of thinking time.

User

[Try in Console](https://console.anthropic.com/workbench/new?user=Develop+a+comprehensive+strategy+for+Microsoft+entering+%0Athe+personalized+medicine+market+by+2027.%0A%0ABegin+with%3A%0A1.+A+Blue+Ocean+Strategy+canvas%0A2.+Apply+Porter%27s+Five+Forces+to+identify+competitive+pressures%0A%0ANext%2C+conduct+a+scenario+planning+exercise+with+four+%0Adistinct+futures+based+on+regulatory+and+technological+variables.%0A%0AFor+each+scenario%3A%0A-+Develop+strategic+responses+using+the+Ansoff+Matrix%0A%0AFinally%2C+apply+the+Three+Horizons+framework+to%3A%0A-+Map+the+transition+pathway%0A-+Identify+potential+disruptive+innovations+at+each+stage&thinking.budget_tokens=16000)

Copy

```text
Develop a comprehensive strategy for Microsoft entering
the personalized medicine market by 2027.

Begin with:
1. A Blue Ocean Strategy canvas
2. Apply Porter's Five Forces to identify competitive pressures

Next, conduct a scenario planning exercise with four
distinct futures based on regulatory and technological variables.

For each scenario:
- Develop strategic responses using the Ansoff Matrix

Finally, apply the Three Horizons framework to:
- Map the transition pathway
- Identify potential disruptive innovations at each stage

```

By specifying multiple analytical frameworks that must be applied sequentially, thinking time naturally increases as Claude works through each framework methodically.

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips\#have-claude-reflect-on-and-check-its-work-for-improved-consistency-and-error-handling)  Have Claude reflect on and check its work for improved consistency and error handling

You can use simple natural language prompting to improve consistency and reduce errors:

1. Ask Claude to verify its work with a simple test before declaring a task complete
2. Instruct the model to analyze whether its previous step achieved the expected result
3. For coding tasks, ask Claude to run through test cases in its extended thinking

Example:

User

[Try in Console](https://console.anthropic.com/workbench/new?user=Write+a+function+to+calculate+the+factorial+of+a+number.+%0ABefore+you+finish%2C+please+verify+your+solution+with+test+cases+for%3A%0A-+n%3D0%0A-+n%3D1%0A-+n%3D5%0A-+n%3D10%0AAnd+fix+any+issues+you+find.&thinking.budget_tokens=16000)

Copy

```text
Write a function to calculate the factorial of a number.
Before you finish, please verify your solution with test cases for:
- n=0
- n=1
- n=5
- n=10
And fix any issues you find.

```

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips\#next-steps)  Next steps

[**Extended thinking cookbook** \\
\\
Explore practical examples of extended thinking in our cookbook.](https://github.com/anthropics/anthropic-cookbook/tree/main/extended_thinking) [**Extended thinking guide** \\
\\
See complete technical documentation for implementing extended thinking.](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking)

Was this page helpful?

YesNo

[Long context tips](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips) [Define success criteria](https://docs.anthropic.com/en/docs/test-and-evaluate/define-success)

On this page

- [Before diving in](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips#before-diving-in)
- [Technical considerations for extended thinking](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips#technical-considerations-for-extended-thinking)
- [Prompting techniques for extended thinking](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips#prompting-techniques-for-extended-thinking)
- [Use general instructions first, then troubleshoot with more step-by-step instructions](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips#use-general-instructions-first%2C-then-troubleshoot-with-more-step-by-step-instructions)
- [Multishot prompting with extended thinking](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips#multishot-prompting-with-extended-thinking)
- [Maximizing instruction following with extended thinking](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips#maximizing-instruction-following-with-extended-thinking)
- [Using extended thinking to debug and steer Claude’s behavior](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips#using-extended-thinking-to-debug-and-steer-claude%E2%80%99s-behavior)
- [Making the best of long outputs and longform thinking](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips#making-the-best-of-long-outputs-and-longform-thinking)
- [Have Claude reflect on and check its work for improved consistency and error handling](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips#have-claude-reflect-on-and-check-its-work-for-improved-consistency-and-error-handling)
- [Next steps](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips#next-steps)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_long-context-tips.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips"
title: "Long context prompting tips - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Long context prompting tips

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips).

Claude’s extended context window (200K tokens for Claude 3 models) enables handling complex, data-rich tasks. This guide will help you leverage this power effectively.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips\#essential-tips-for-long-context-prompts)  Essential tips for long context prompts

- **Put longform data at the top**: Place your long documents and inputs (~20K+ tokens) near the top of your prompt, above your query, instructions, and examples. This can significantly improve Claude’s performance across all models.







Queries at the end can improve response quality by up to 30% in tests, especially with complex, multi-document inputs.

- **Structure document content and metadata with XML tags**: When using multiple documents, wrap each document in `<document>` tags with `<document_content>` and `<source>` (and other metadata) subtags for clarity.








Example multi-document structure










Copy









```xml
<documents>
    <document index="1">
      <source>annual_report_2023.pdf</source>
      <document_content>
        {{ANNUAL_REPORT}}
      </document_content>
    </document>
    <document index="2">
      <source>competitor_analysis_q2.xlsx</source>
      <document_content>
        {{COMPETITOR_ANALYSIS}}
      </document_content>
    </document>
</documents>

Analyze the annual report and competitor analysis. Identify strategic advantages and recommend Q3 focus areas.

```

- **Ground responses in quotes**: For long document tasks, ask Claude to quote relevant parts of the documents first before carrying out its task. This helps Claude cut through the “noise” of the rest of the document’s contents.








Example quote extraction










Copy









```xml
You are an AI physician's assistant. Your task is to help doctors diagnose possible patient illnesses.

<documents>
    <document index="1">
      <source>patient_symptoms.txt</source>
      <document_content>
        {{PATIENT_SYMPTOMS}}
      </document_content>
    </document>
    <document index="2">
      <source>patient_records.txt</source>
      <document_content>
        {{PATIENT_RECORDS}}
      </document_content>
    </document>
    <document index="3">
      <source>patient01_appt_history.txt</source>
      <document_content>
        {{PATIENT01_APPOINTMENT_HISTORY}}
      </document_content>
    </document>
</documents>

Find quotes from the patient records and appointment history that are relevant to diagnosing the patient's reported symptoms. Place these in <quotes> tags. Then, based on these quotes, list all information that would help the doctor diagnose the patient's symptoms. Place your diagnostic information in <info> tags.

```


* * *

[**Prompt library** \\
\\
Get inspired by a curated selection of prompts for various tasks and use cases.](https://docs.anthropic.com/en/resources/prompt-library/library) [**GitHub prompting tutorial** \\
\\
An example-filled tutorial that covers the prompt engineering concepts found in our docs.](https://github.com/anthropics/prompt-eng-interactive-tutorial) [**Google Sheets prompting tutorial** \\
\\
A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8)

Was this page helpful?

YesNo

[Chain complex prompts](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts) [Extended thinking tips](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips)

On this page

- [Essential tips for long context prompts](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips#essential-tips-for-long-context-prompts)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_multishot-prompting.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting"
title: "Use examples (multishot prompting) to guide Claude's behavior - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Use examples (multishot prompting) to guide Claude's behavior

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips).

Examples are your secret weapon shortcut for getting Claude to generate exactly what you need. By providing a few well-crafted examples in your prompt, you can dramatically improve the accuracy, consistency, and quality of Claude’s outputs.
This technique, known as few-shot or multishot prompting, is particularly effective for tasks that require structured outputs or adherence to specific formats.

**Power up your prompts**: Include 3-5 diverse, relevant examples to show Claude exactly what you want. More examples = better performance, especially for complex tasks.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting\#why-use-examples%3F)  Why use examples?

- **Accuracy**: Examples reduce misinterpretation of instructions.
- **Consistency**: Examples enforce uniform structure and style.
- **Performance**: Well-chosen examples boost Claude’s ability to handle complex tasks.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting\#crafting-effective-examples)  Crafting effective examples

For maximum effectiveness, make sure that your examples are:

- **Relevant**: Your examples mirror your actual use case.
- **Diverse**: Your examples cover edge cases and potential challenges, and vary enough that Claude doesn’t inadvertently pick up on unintended patterns.
- **Clear**: Your examples are wrapped in `<example>` tags (if multiple, nested within `<examples>` tags) for structure.

Ask Claude to evaluate your examples for relevance, diversity, or clarity. Or have Claude generate more examples based on your initial set.

Example: Analyzing customer feedback

Notice that in the “no examples” version, Claude does not list multiple options for each category, despite its written analysis indicating that there are multiple categories for certain feedback. It also includes a long explanation when we may not want it to.

| Role | No Examples | With Examples |
| --- | --- | --- |
| User | Analyze this customer feedback and categorize the issues. Use these categories: UI/UX, Performance, Feature Request, Integration, Pricing, and Other. Also rate the sentiment (Positive/Neutral/Negative) and priority (High/Medium/Low).<br>Here is the feedback: {{FEEDBACK}} | Our CS team is overwhelmed with unstructured feedback. Your task is to analyze feedback and categorize issues for our product and engineering teams. Use these categories: UI/UX, Performance, Feature Request, Integration, Pricing, and Other. Also rate the sentiment (Positive/Neutral/Negative) and priority (High/Medium/Low). Here is an example:<br><example><br>Input: The new dashboard is a mess! It takes forever to load, and I can’t find the export button. Fix this ASAP!<br>Category: UI/UX, Performance<br>Sentiment: Negative<br>Priority: High</example><br>Now, analyze this feedback: {{FEEDBACK}} |
| Assistant (Claude’s response) | Here’s the analysis of the customer feedback:<br>Issue: UI/UX<br>Sentiment: Negative<br>Priority: High<br>The customer is frustrated with the new dashboard design, which they find cluttered and slow to load. They specifically call out the missing “export” button, which is likely a critical feature. This issue needs to be addressed as a high priority.<br>Issue: Integration<br>Sentiment: Positive<br>Priority: Medium<br>The customer is pleased with the existing Salesforce integration but would like to see support for Hubspot as well. This is a feature request that could be considered for a future product update.<br>Issue: Pricing<br>Sentiment: Negative<br>Priority: High<br>The customer finds the pricing to be unreasonable, especially for the basic features. They are threatening to switch to a competitor, so this is a high-priority issue that needs to be reviewed.<br>Issue: Performance<br>Sentiment Negative<br>Priority: High<br>The customer is experiencing critical issues with the mobile app, where large file uploads consistently result in crashes. This is a significant problem that impacts the customer’s ability to use the product effectively and should be addressed as a high priority.<br>Issue: UI/UX<br>Sentiment: Positive<br>Priority: Low<br>The customer is overall satisfied with the product, specifically calling out the intuitive UI and excellent customer support. This is a positive piece of feedback that does not require any immediate action. | Here’s the analysis of the customer feedback:<br>1\. The new dashboard is a mess! It takes forever to load, and I can’t find the export button. Fix this ASAP!<br>Category: UI/UX, Performance<br>Sentiment: Negative<br>Priority: High<br>2\. Love the Salesforce integration! But it’d be great if you could add Hubspot too.<br>Category: Integration, Feature Request<br>Sentiment: Positive<br>Priority: Medium<br>3\. Your pricing is ridiculous! $99/mo for basic features? I’m switching to Competitor X.<br>Category: Pricing<br>Sentiment: Negative<br>Priority: High<br>4\. The mobile app keeps crashing when I try to upload large files (>50MB). This is critical for our field agents.<br>Category: Performance<br>Sentiment: Negative<br>Priority: High<br>5\. Overall, I’m happy with the product. The UI is intuitive, and the customer support is top-notch. Keep it up!<br>Category: UI/UX, Other (Customer Support)<br>Sentiment: Positive<br>Priority: Low |

* * *

[**Prompt library** \\
\\
Get inspired by a curated selection of prompts for various tasks and use cases.](https://docs.anthropic.com/en/resources/prompt-library/library) [**GitHub prompting tutorial** \\
\\
An example-filled tutorial that covers the prompt engineering concepts found in our docs.](https://github.com/anthropics/prompt-eng-interactive-tutorial) [**Google Sheets prompting tutorial** \\
\\
A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8)

Was this page helpful?

YesNo

[Be clear and direct](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct) [Let Claude think (CoT)](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought)

On this page

- [Why use examples?](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting#why-use-examples%3F)
- [Crafting effective examples](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting#crafting-effective-examples)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_overview.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview"
title: "Prompt engineering overview - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Prompt engineering overview

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips).

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview\#before-prompt-engineering)  Before prompt engineering

This guide assumes that you have:

1. A clear definition of the success criteria for your use case
2. Some ways to empirically test against those criteria
3. A first draft prompt you want to improve

If not, we highly suggest you spend time establishing that first. Check out [Define your success criteria](https://docs.anthropic.com/en/docs/test-and-evaluate/define-success) and [Create strong empirical evaluations](https://docs.anthropic.com/en/docs/test-and-evaluate/develop-tests) for tips and guidance.

[**Prompt generator** \\
\\
Don’t have a first draft prompt? Try the prompt generator in the Anthropic Console!](https://console.anthropic.com/dashboard)

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview\#when-to-prompt-engineer)  When to prompt engineer

This guide focuses on success criteria that are controllable through prompt engineering.
Not every success criteria or failing eval is best solved by prompt engineering. For example, latency and cost can be sometimes more easily improved by selecting a different model.

Prompting vs. finetuning

Prompt engineering is far faster than other methods of model behavior control, such as finetuning, and can often yield leaps in performance in far less time. Here are some reasons to consider prompt engineering over finetuning:

- **Resource efficiency**: Fine-tuning requires high-end GPUs and large memory, while prompt engineering only needs text input, making it much more resource-friendly.
- **Cost-effectiveness**: For cloud-based AI services, fine-tuning incurs significant costs. Prompt engineering uses the base model, which is typically cheaper.
- **Maintaining model updates**: When providers update models, fine-tuned versions might need retraining. Prompts usually work across versions without changes.
- **Time-saving**: Fine-tuning can take hours or even days. In contrast, prompt engineering provides nearly instantaneous results, allowing for quick problem-solving.
- **Minimal data needs**: Fine-tuning needs substantial task-specific, labeled data, which can be scarce or expensive. Prompt engineering works with few-shot or even zero-shot learning.
- **Flexibility & rapid iteration**: Quickly try various approaches, tweak prompts, and see immediate results. This rapid experimentation is difficult with fine-tuning.
- **Domain adaptation**: Easily adapt models to new domains by providing domain-specific context in prompts, without retraining.
- **Comprehension improvements**: Prompt engineering is far more effective than finetuning at helping models better understand and utilize external content such as retrieved documents
- **Preserves general knowledge**: Fine-tuning risks catastrophic forgetting, where the model loses general knowledge. Prompt engineering maintains the model’s broad capabilities.
- **Transparency**: Prompts are human-readable, showing exactly what information the model receives. This transparency aids in understanding and debugging.

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview\#how-to-prompt-engineer)  How to prompt engineer

The prompt engineering pages in this section have been organized from most broadly effective techniques to more specialized techniques. When troubleshooting performance, we suggest you try these techniques in order, although the actual impact of each technique will depend on your use case.

1. [Prompt generator](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator)
2. [Be clear and direct](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct)
3. [Use examples (multishot)](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting)
4. [Let Claude think (chain of thought)](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought)
5. [Use XML tags](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags)
6. [Give Claude a role (system prompts)](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts)
7. [Prefill Claude’s response](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response)
8. [Chain complex prompts](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts)
9. [Long context tips](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips)

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview\#prompt-engineering-tutorial)  Prompt engineering tutorial

If you’re an interactive learner, you can dive into our interactive tutorials instead!

[**GitHub prompting tutorial** \\
\\
An example-filled tutorial that covers the prompt engineering concepts found in our docs.](https://github.com/anthropics/prompt-eng-interactive-tutorial) [**Google Sheets prompting tutorial** \\
\\
A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8)

Was this page helpful?

YesNo

[Legal summarization](https://docs.anthropic.com/en/docs/about-claude/use-case-guides/legal-summarization) [Claude 4 best practices](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices)

On this page

- [Before prompt engineering](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview#before-prompt-engineering)
- [When to prompt engineer](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview#when-to-prompt-engineer)
- [How to prompt engineer](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview#how-to-prompt-engineer)
- [Prompt engineering tutorial](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview#prompt-engineering-tutorial)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_prefill-claudes-response.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response"
title: "Prefill Claude's response for greater output control - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Prefill Claude's response for greater output control

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips).

Prefilling is only available for non-extended thinking modes. It’s not currently supported with extended thinking.

When using Claude, you have the unique ability to guide its responses by prefilling the `Assistant` message. This powerful technique allows you to direct Claude’s actions, skip preambles, enforce specific formats like JSON or XML, and even help Claude maintain character consistency in role-play scenarios.

In some cases where Claude is not performing as expected, a few prefilled sentences can vastly improve Claude’s performance. A little prefilling goes a long way!

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response\#how-to-prefill-claude%E2%80%99s-response)  How to prefill Claude’s response

To prefill, include the desired initial text in the `Assistant` message (Claude’s response will continue from where the `Assistant` message leaves off):

Copy

```python
import anthropic

client = anthropic.Anthropic()
response = client.messages.create(
    model="claude-opus-4-20250514",
    max_tokens=1024,
    messages=[\
        {"role": "user", "content": "What is your favorite color?"},\
        {"role": "assistant", "content": "As an AI assistant, I don't have a favorite color, But if I had to pick, it would be green because"}  # Prefill here\
    ]
)

```

The prefill content cannot end with trailing whitespace. A prefill like `"As an AI assistant, I "` (with a space at the end) will result in an error.

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response\#examples)  Examples

#### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response\#example-1%3A-controlling-output-formatting-and-skipping-the-preamble)  Example 1: Controlling output formatting and skipping the preamble

**Power user tip**: Prefilling `{` forces Claude to skip the preamble and directly output the JSON object. This is cleaner, more concise, and easier for programs to parse without additional processing.

Example: Structured data extraction without prefilling

| Role | Content |
| --- | --- |
| User | Extract the name, size, price, and color from this product description as a JSON object:<br><description><br>The SmartHome Mini is a compact smart home assistant available in black or white for only $49.99. At just 5 inches wide, it lets you control lights, thermostats, and other connected devices via voice or app,no matter where you place it in your home. This affordable little hub brings convenient hands-free control to your smart devices.<br></description> |
| Assistant | Here’s the extracted information in JSON format:<br>\`\`\`json<br>{<br> “name”: “SmartHome Mini”,<br> “size”: “5 inches wide”,<br> “price”: “$49.99”,<br> “colors”: \[“black”, “white”\]<br>}<br>\`\`\`<br>I’ve extracted the following details from the product description:<br>\- **Name**: SmartHome Mini<br>\- **Size**: 5 inches wide<br>\- **Price**: $49.99<br>\- **Colors**: Available in black and white<br>The JSON object provides a structured format that’s easy for programs to parse and use. Let me know if you need any modifications or have any other questions! |

Example: Structured data extraction with prefilling

| Role | Content |
| --- | --- |
| User | Extract the name, size, price, and color from this product description as a JSON object:<br><description><br>The SmartHome Mini is a compact smart home assistant available in black or white for only $49.99. At just 5 inches wide, it lets you control lights, thermostats, and other connected devices via voice or app,no matter where you place it in your home. This affordable little hub brings convenient hands-free control to your smart devices.<br></description> |
| Assistant (prefill) | { |
| Assistant (Claude’s response) | “name”: “SmartHome Mini”,<br>“size”: “5 inches wide”,<br>“price”: “$49.99”,<br>“colors”: \[<br> “black”,<br> “white”<br>\]<br>} |

#### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response\#example-2%3A-maintaining-character-in-roleplay-scenarios)  Example 2: Maintaining character in roleplay scenarios

**Role-play tip**: Prefilling a bracketed `[ROLE_NAME]` can remind Claude stay in character, even for longer and more complex conversations. This is especially powerful when combined with role prompting in the `system` parameter.

Example: Maintaining character without role prompting

| Role | Content |
| --- | --- |
| User (50 conversation turns in with “Sherlock Holmes” Claude) | What do you deduce about the owner of this shoe? <image>muddy\_shoe.jpg</image> |
| Assistant | As an AI assistant, I would be happy to analyze the image of a muddy shoe as if you had provided it. Here’s my deduction… |

Example: Maintaining character with role prompting

| Role | Content |
| --- | --- |
| User (50 conversation turns in with “Sherlock Holmes” Claude) | What do you deduce about the owner of this shoe? <br><image>muddy\_shoe.jpg</image> |
| Assistant (prefill) | \[Sherlock Holmes\] |
| Assistant (Claude’s response) | Ah, what have we here? A most curious specimen, Watson! Let us examine this shoe with a discerning eye. The mud, you see, is not your common London clay, but rather the distinctive reddish hue of the iron-rich soil found only in the environs of Hampstead Heath. And yet, the wear on the sole suggests a gait more suited to the cobblestones of Whitechapel than the gentle slopes of the Heath.<br>Now, observe the laces! They are tied with a particular knot favored by those in the medical profession,doubtless a habit acquired during years of tying surgical gowns. But the scuff marks on the toe box tell a different tale: they are consistent with the kicking motion one might employ in the martial arts, specifically Baritsu.<br>We may conclude, then, that our absent shoe owner is a doctor, possibly a surgeon, who resides in Whitechapel but frequents Hampstead Heath,perhaps for a secret Baritsu practice, away from prying eyes. A most intriguing case, Watson! We must make haste; the game is afoot! |

* * *

[**Prompt library** \\
\\
Get inspired by a curated selection of prompts for various tasks and use cases.](https://docs.anthropic.com/en/resources/prompt-library/library) [**GitHub prompting tutorial** \\
\\
An example-filled tutorial that covers the prompt engineering concepts found in our docs.](https://github.com/anthropics/prompt-eng-interactive-tutorial) [**Google Sheets prompting tutorial** \\
\\
A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8)

Was this page helpful?

YesNo

[Give Claude a role (system prompts)](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts) [Chain complex prompts](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts)

On this page

- [How to prefill Claude’s response](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response#how-to-prefill-claude%E2%80%99s-response)
- [Examples](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response#examples)
- [Example 1: Controlling output formatting and skipping the preamble](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response#example-1%3A-controlling-output-formatting-and-skipping-the-preamble)
- [Example 2: Maintaining character in roleplay scenarios](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response#example-2%3A-maintaining-character-in-roleplay-scenarios)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_prompt-generator.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator"
title: "Automatically generate first draft prompt templates - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Automatically generate first draft prompt templates

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

Our prompt generator is compatible with all Claude models, including those with extended thinking capabilities. For prompting tips specific to extended thinking models, see [here](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking).

Sometimes, the hardest part of using an AI model is figuring out how to prompt it effectively. To help with this, we’ve created a prompt generation tool that guides Claude to generate high-quality prompt templates tailored to your specific tasks. These templates follow many of our prompt engineering best practices.

The prompt generator is particularly useful as a tool for solving the “blank page problem” to give you a jumping-off point for further testing and iteration.

Try the prompt generator now directly on the [Console](https://console.anthropic.com/dashboard).

If you’re interested in analyzing the underlying prompt and architecture, check out our [prompt generator Google Colab notebook](https://anthropic.com/metaprompt-notebook/). There, you can easily run the code to have Claude construct prompts on your behalf.

Note that to run the Colab notebook, you will need an [API key](https://console.anthropic.com/settings/keys).

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator\#next-steps)  Next steps

[**Start prompt engineering** \\
\\
Get inspired by a curated selection of prompts for various tasks and use cases.](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct) [**Prompt library** \\
\\
Get inspired by a curated selection of prompts for various tasks and use cases.](https://docs.anthropic.com/en/resources/prompt-library/library) [**GitHub prompting tutorial** \\
\\
An example-filled tutorial that covers the prompt engineering concepts found in our docs.](https://github.com/anthropics/prompt-eng-interactive-tutorial) [**Google Sheets prompting tutorial** \\
\\
A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8)

Was this page helpful?

YesNo

[Claude 4 best practices](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices) [Use prompt templates](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables)

On this page

- [Next steps](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator#next-steps)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_prompt-improver.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver"
title: "Use our prompt improver to optimize your prompts - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Use our prompt improver to optimize your prompts

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

Our prompt improver is compatible with all Claude models, including those with extended thinking capabilities. For prompting tips specific to extended thinking models, see [here](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking).

The prompt improver helps you quickly iterate and improve your prompts through automated analysis and enhancement. It excels at making prompts more robust for complex tasks that require high accuracy.

![](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/images/prompt_improver.png)

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver\#before-you-begin)  Before you begin

You’ll need:

- A [prompt template](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables) to improve
- Feedback on current issues with Claude’s outputs (optional but recommended)
- Example inputs and ideal outputs (optional but recommended)

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver\#how-the-prompt-improver-works)  How the prompt improver works

The prompt improver enhances your prompts in 4 steps:

1. **Example identification**: Locates and extracts examples from your prompt template
2. **Initial draft**: Creates a structured template with clear sections and XML tags
3. **Chain of thought refinement**: Adds and refines detailed reasoning instructions
4. **Example enhancement**: Updates examples to demonstrate the new reasoning process

You can watch these steps happen in real-time in the improvement modal.

![](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/images/prompt_improver_modal.png)

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver\#what-you-get)  What you get

The prompt improver generates templates with:

- Detailed chain-of-thought instructions that guide Claude’s reasoning process and typically improve its performance
- Clear organization using XML tags to separate different components
- Standardized example formatting that demonstrates step-by-step reasoning from input to output
- Strategic prefills that guide Claude’s initial responses

While examples appear separately in the Workbench UI, they’re included at the start of the first user message in the actual API call. View the raw format by clicking ” **</\> Get Code**” or insert examples as raw text via the Examples box.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver\#how-to-use-the-prompt-improver)  How to use the prompt improver

1. Submit your prompt template
2. Add any feedback about issues with Claude’s current outputs (e.g., “summaries are too basic for expert audiences”)
3. Include example inputs and ideal outputs
4. Review the improved prompt

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver\#generate-test-examples)  Generate test examples

Don’t have examples yet? Use our [Test Case Generator](https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool#creating-test-cases) to:

1. Generate sample inputs
2. Get Claude’s responses
3. Edit the responses to match your ideal outputs
4. Add the polished examples to your prompt

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver\#when-to-use-the-prompt-improver)  When to use the prompt improver

The prompt improver works best for:

- Complex tasks requiring detailed reasoning
- Situations where accuracy is more important than speed
- Problems where Claude’s current outputs need significant improvement

For latency or cost-sensitive applications, consider using simpler prompts. The prompt improver creates templates that produce longer, more thorough, but slower responses.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver\#example-improvement)  Example improvement

Here’s how the prompt improver enhances a basic classification prompt:

Original prompt

Copy

```
From the following list of Wikipedia article titles, identify which article this sentence came from.
Respond with just the article title and nothing else.

Article titles:
{{titles}}

Sentence to classify:
{{sentence}}

```

Improved prompt

Copy

```
You are an intelligent text classification system specialized in matching sentences to Wikipedia article titles. Your task is to identify which Wikipedia article a given sentence most likely belongs to, based on a provided list of article titles.

First, review the following list of Wikipedia article titles:
<article_titles>
{{titles}}
</article_titles>

Now, consider this sentence that needs to be classified:
<sentence_to_classify>
{{sentence}}
</sentence_to_classify>

Your goal is to determine which article title from the provided list best matches the given sentence. Follow these steps:

1. List the key concepts from the sentence
2. Compare each key concept with the article titles
3. Rank the top 3 most relevant titles and explain why they are relevant
4. Select the most appropriate article title that best encompasses or relates to the sentence's content

Wrap your analysis in <analysis> tags. Include the following:
- List of key concepts from the sentence
- Comparison of each key concept with the article titles
- Ranking of top 3 most relevant titles with explanations
- Your final choice and reasoning

After your analysis, provide your final answer: the single most appropriate Wikipedia article title from the list.

Output only the chosen article title, without any additional text or explanation.

```

Notice how the improved prompt:

- Adds clear step-by-step reasoning instructions
- Uses XML tags to organize content
- Provides explicit output formatting requirements
- Guides Claude through the analysis process

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver\#troubleshooting)  Troubleshooting

Common issues and solutions:

- **Examples not appearing in output**: Check that examples are properly formatted with XML tags and appear at the start of the first user message
- **Chain of thought too verbose**: Add specific instructions about desired output length and level of detail
- **Reasoning steps don’t match your needs**: Modify the steps section to match your specific use case

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver\#next-steps)  Next steps

[**Prompt library** \\
\\
Get inspired by example prompts for various tasks.](https://docs.anthropic.com/en/resources/prompt-library/library) [**GitHub prompting tutorial** \\
\\
Learn prompting best practices with our interactive tutorial.](https://github.com/anthropics/prompt-eng-interactive-tutorial) [**Test your prompts** \\
\\
Use our evaluation tool to test your improved prompts.](https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool)

Was this page helpful?

YesNo

[Use prompt templates](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables) [Be clear and direct](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct)

On this page

- [Before you begin](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver#before-you-begin)
- [How the prompt improver works](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver#how-the-prompt-improver-works)
- [What you get](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver#what-you-get)
- [How to use the prompt improver](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver#how-to-use-the-prompt-improver)
- [Generate test examples](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver#generate-test-examples)
- [When to use the prompt improver](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver#when-to-use-the-prompt-improver)
- [Example improvement](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver#example-improvement)
- [Troubleshooting](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver#troubleshooting)
- [Next steps](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver#next-steps)

![](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/images/prompt_improver.png)

![](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/images/prompt_improver_modal.png)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_prompt-templates-and-variables.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables"
title: "Use prompt templates and variables - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Use prompt templates and variables

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

When deploying an LLM-based application with Claude, your API calls will typically consist of two types of content:

- **Fixed content:** Static instructions or context that remain constant across multiple interactions
- **Variable content:** Dynamic elements that change with each request or conversation, such as:

  - User inputs
  - Retrieved content for Retrieval-Augmented Generation (RAG)
  - Conversation context such as user account history
  - System-generated data such as tool use results fed in from other independent calls to Claude

A **prompt template** combines these fixed and variable parts, using placeholders for the dynamic content. In the [Anthropic Console](https://console.anthropic.com/), these placeholders are denoted with **{{double brackets}}**, making them easily identifiable and allowing for quick testing of different values.

* * *

# [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables\#when-to-use-prompt-templates-and-variables)  When to use prompt templates and variables

You should always use prompt templates and variables when you expect any part of your prompt to be repeated in another call to Claude (only via the API or the [Anthropic Console](https://console.anthropic.com/). [claude.ai](https://claude.ai/) currently does not support prompt templates or variables).

Prompt templates offer several benefits:

- **Consistency:** Ensure a consistent structure for your prompts across multiple interactions
- **Efficiency:** Easily swap out variable content without rewriting the entire prompt
- **Testability:** Quickly test different inputs and edge cases by changing only the variable portion
- **Scalability:** Simplify prompt management as your application grows in complexity
- **Version control:** Easily track changes to your prompt structure over time by keeping tabs only on the core part of your prompt, separate from dynamic inputs

The [Anthropic Console](https://console.anthropic.com/) heavily uses prompt templates and variables in order to support features and tooling for all the above, such as with the:

- **[Prompt generator](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator):** Decides what variables your prompt needs and includes them in the template it outputs
- **[Prompt improver](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver):** Takes your existing template, including all variables, and maintains them in the improved template it outputs
- **[Evaluation tool](https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool):** Allows you to easily test, scale, and track versions of your prompts by separating the variable and fixed portions of your prompt template

* * *

# [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables\#example-prompt-template)  Example prompt template

Let’s consider a simple application that translates English text to Spanish. The translated text would be variable since you would expect this text to change between users or calls to Claude. This translated text could be dynamically retrieved from databases or the user’s input.

Thus, for your translation app, you might use this simple prompt template:

Copy

```
Translate this text from English to Spanish: {{text}}

```

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables\#next-steps)  Next steps

[**Generate a prompt** \\
\\
Learn about the prompt generator in the Anthropic Console and try your hand at getting Claude to generate a prompt for you.](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator) [**Apply XML tags** \\
\\
If you want to level up your prompt variable game, wrap them in XML tags.](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags) [**Anthropic Console** \\
\\
Check out the myriad prompt development tools available in the Anthropic Console.](https://console.anthropic.com/)

Was this page helpful?

YesNo

[Prompt generator](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator) [Prompt improver](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver)

On this page

- [When to use prompt templates and variables](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables#when-to-use-prompt-templates-and-variables)
- [Example prompt template](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables#example-prompt-template)
- [Next steps](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables#next-steps)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_system-prompts.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts"
title: "Giving Claude a role with a system prompt - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Giving Claude a role with a system prompt

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips).

When using Claude, you can dramatically improve its performance by using the `system` parameter to give it a role. This technique, known as role prompting, is the most powerful way to use system prompts with Claude.

The right role can turn Claude from a general assistant into your virtual domain expert!

**System prompt tips**: Use the `system` parameter to set Claude’s role. Put everything else, like task-specific instructions, in the `user` turn instead.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts\#why-use-role-prompting%3F)  Why use role prompting?

- **Enhanced accuracy:** In complex scenarios like legal analysis or financial modeling, role prompting can significantly boost Claude’s performance.
- **Tailored tone:** Whether you need a CFO’s brevity or a copywriter’s flair, role prompting adjusts Claude’s communication style.
- **Improved focus:** By setting the role context, Claude stays more within the bounds of your task’s specific requirements.

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts\#how-to-give-claude-a-role)  How to give Claude a role

Use the `system` parameter in the [Messages API](https://docs.anthropic.com/en/api/messages) to set Claude’s role:

Copy

```python
import anthropic

client = anthropic.Anthropic()

response = client.messages.create(
    model="claude-3-7-sonnet-20250219",
    max_tokens=2048,
    system="You are a seasoned data scientist at a Fortune 500 company.", # <-- role prompt
    messages=[\
        {"role": "user", "content": "Analyze this dataset for anomalies: <dataset>{{DATASET}}</dataset>"}\
    ]
)

print(response.content)

```

**Role prompting tip**: Experiment with roles! A `data scientist` might see different insights than a `marketing strategist` for the same data. A `data scientist specializing in customer insight analysis for Fortune 500 companies` might yield different results still!

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts\#examples)  Examples

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts\#example-1%3A-legal-contract-analysis)  Example 1: Legal contract analysis

Without a role, Claude might miss critical issues:

Legal contract analysis without role prompting

| Role | Content |
| --- | --- |
| User | Analyze this software licensing agreement for potential risks:<br><contract><br>{{CONTRACT}}<br></contract><br>Focus on indemnification, liability, and IP ownership. |
| Assistant | Here’s a summary of the key points in the software licensing agreement:<br>1\. Indemnification (Section 8):<br> \- We indemnify the vendor against claims arising from our use.<br>2\. Limitation of Liability (Section 9):<br> \- Damages capped at $500.<br>3\. IP Ownership (Section 12):<br> \- We retain ownership of our modifications.<br>Overall, the agreement seems standard. The indemnification and liability clauses are typical, and we maintain our IP rights. |

With a role, Claude catches critical issues that could cost millions:

Legal contract analysis with role prompting

| Role | Content |
| --- | --- |
| User | You are the General Counsel of a Fortune 500 tech company. We’re considering this software licensing agreement for our core data infrastructure:<br><contract><br>{{CONTRACT}}<br></contract><br>Analyze it for potential risks, focusing on indemnification, liability, and IP ownership. Give your professional opinion. |
| Assistant | I’ve reviewed the software licensing agreement, and I have serious concerns that could expose our company to significant risks:<br>1\. Indemnification (Section 8):<br> \- Critical Issue: We indemnify the vendor against “any and all claims” arising from our use.<br> \- Risk: This could hold us liable even for the vendor’s negligence or product defects.<br> \- Recommendation: Reject. Limit our indemnity to claims arising from our violation of the agreement.<br>2\. Limitation of Liability (Section 9):<br> \- Critical Issue: Damages capped at $500, including direct damages.<br> \- Risk: Grossly inadequate. A critical failure in our data infrastructure could cost us millions in lost revenue and reputational damage.<br> \- Recommendation: Reject. Negotiate for cap at 12 months of fees for direct damages, and carve-outs for data breaches.<br>3\. IP Ownership (Section 12):<br> \- Critical Issue: Vendor gains joint ownership of our modifications and integrations.<br> \- Risk: They could use or sell our proprietary algorithms or data insights to competitors.<br> \- Recommendation: Reject. We must retain full ownership of our work.<br>Professional Opinion: Do not sign this agreement. It is grossly unfavorable and exposes us to unacceptable levels of risk. If the vendor refuses to renegotiate these terms, I strongly advise exploring alternative providers or accelerating our in-house solution. The potential costs of proceeding with this agreement far outweigh any short-term gains. |

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts\#example-2%3A-financial-analysis)  Example 2: Financial analysis

Without a role, Claude’s analysis lacks depth:

Financial analysis without role prompting

| Role | Content |
| --- | --- |
| User | Analyze this dataset of our Q2 financials:<br><data><br>{{FINANCIALS}}<br></data><br>Highlight key trends and recommend actions. |
| Assistant | Here’s a summary of your Q2 financials:<br>1\. Revenue: $15.2M, up 22% YoY. Enterprise client base grew 30%.<br>2\. Gross Margin: 72%, up 3% from Q1.<br>3\. EBITDA Margin: 18%, down 2% due to R&D investments.<br>4\. Cash Flow: $4.1M operating, $28M in reserves.<br>Overall, financials look strong with revenue growth and healthy margins. Increased R&D spending is impacting profitability but could pay off long-term. Maintain current course. |

With a role, Claude delivers actionable insights:

Financial analysis with role prompting

| Role | Content |
| --- | --- |
| User | You are the CFO of a high-growth B2B SaaS company. We’re in a board meeting discussing our Q2 financials:<br><data><br>{{FINANCIALS}}<br></data><br>Analyze key trends, flag concerns, and recommend strategic actions. Our investors want aggressive growth but are wary of our burn rate. |
| Assistant | Board members, here’s my analysis of our Q2 financials:<br>1\. Revenue ($15.2M, +22% YoY):<br> \- Insight: Enterprise growth (+30%) is outpacing overall growth.<br> \- Flag: SMB segment declined 5%.<br> \- Action: Reallocate 20% of SMB marketing budget to enterprise sales. Task product to simplify SMB onboarding.<br>2\. Margins (Gross: 72%, +3% QoQ; EBITDA: 18%, -2% QoQ):<br> \- Insight: Infrastructure optimizations boosted gross margins.<br> \- Flag: R&D spend on AI features dented EBITDA.<br> \- Action: No change. Our AI roadmap is critical for enterprise stickiness.<br>3\. Cash ($4.1M OCF, $28M reserves):<br> \- Insight: 15-month runway at current burn.<br> \- Flag: CAC up 20%, eroding LTV/CAC.<br> \- Action: Freeze non-essential hires. Implement sales funnel analytics to cut CAC by 15% in Q3.<br>Strategic Stance: We’re threading the needle between growth and burn. Enterprise focus is our growth engine,invest there. But watch SMB churn; it could bleed into enterprise. Our AI bet is sound, but we must convert it to ARR by Q4, or we cut R&D by 30%.<br>In sum: Double down on enterprise, streamline SMB, optimize sales, and monetize AI. Questions? |

* * *

[**Prompt library** \\
\\
Get inspired by a curated selection of prompts for various tasks and use cases.](https://docs.anthropic.com/en/resources/prompt-library/library) [**GitHub prompting tutorial** \\
\\
An example-filled tutorial that covers the prompt engineering concepts found in our docs.](https://github.com/anthropics/prompt-eng-interactive-tutorial) [**Google Sheets prompting tutorial** \\
\\
A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8)

Was this page helpful?

YesNo

[Use XML tags](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags) [Prefill Claude's response](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response)

On this page

- [Why use role prompting?](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts#why-use-role-prompting%3F)
- [How to give Claude a role](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts#how-to-give-claude-a-role)
- [Examples](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts#examples)
- [Example 1: Legal contract analysis](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts#example-1%3A-legal-contract-analysis)
- [Example 2: Financial analysis](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts#example-2%3A-financial-analysis)

### docs.anthropic.com_en_docs_build-with-claude_prompt-engineering_use-xml-tags.md

---
url: "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags"
title: "Use XML tags to structure your prompts - Anthropic"
---

[Anthropic home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/anthropic/logo/dark.svg)](https://docs.anthropic.com/)

English

Search...

Ctrl K

Search...

Navigation

Prompt engineering

Use XML tags to structure your prompts

[Welcome](https://docs.anthropic.com/en/home) [Developer Platform](https://docs.anthropic.com/en/docs/intro) [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/mcp) [API Reference](https://docs.anthropic.com/en/api/messages) [Resources](https://docs.anthropic.com/en/resources/overview) [Release Notes](https://docs.anthropic.com/en/release-notes/overview)

While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips).

When your prompts involve multiple components like context, instructions, and examples, XML tags can be a game-changer. They help Claude parse your prompts more accurately, leading to higher-quality outputs.

**XML tip**: Use tags like `<instructions>`, `<example>`, and `<formatting>` to clearly separate different parts of your prompt. This prevents Claude from mixing up instructions with examples or context.

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags\#why-use-xml-tags%3F)  Why use XML tags?

- **Clarity:** Clearly separate different parts of your prompt and ensure your prompt is well structured.
- **Accuracy:** Reduce errors caused by Claude misinterpreting parts of your prompt.
- **Flexibility:** Easily find, add, remove, or modify parts of your prompt without rewriting everything.
- **Parseability:** Having Claude use XML tags in its output makes it easier to extract specific parts of its response by post-processing.

There are no canonical “best” XML tags that Claude has been trained with in particular, although we recommend that your tag names make sense with the information they surround.

* * *

## [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags\#tagging-best-practices)  Tagging best practices

1. **Be consistent**: Use the same tag names throughout your prompts, and refer to those tag names when talking about the content (e.g, `Using the contract in <contract> tags...`).
2. **Nest tags**: You should nest tags `<outer><inner></inner></outer>` for hierarchical content.

**Power user tip**: Combine XML tags with other techniques like multishot prompting ( `<examples>`) or chain of thought ( `<thinking>`, `<answer>`). This creates super-structured, high-performance prompts.

### [​](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags\#examples)  Examples

Example: Generating financial reports

Without XML tags, Claude misunderstands the task and generates a report that doesn’t match the required structure or tone. After substitution, there is also a chance that Claude misunderstands where one section (like the the Q1 report example) stops and another begins.

| Role | No XML Tags | With XML Tags |
| --- | --- | --- |
| User | You’re a financial analyst at AcmeCorp. Generate a Q2 financial report for our investors. Include sections on Revenue Growth, Profit Margins, and Cash Flow, like with this example from last year: {{Q1\_REPORT}}. Use data points from this spreadsheet: {{SPREADSHEET\_DATA}}. The report should be extremely concise, to the point, professional, and in list format. It should and highlight both strengths and areas for improvement. | You’re a financial analyst at AcmeCorp. Generate a Q2 financial report for our investors.<br>AcmeCorp is a B2B SaaS company. Our investors value transparency and actionable insights.<br>Use this data for your report:<data>{{SPREADSHEET\_DATA}}</data><br><instructions><br>1\. Include sections: Revenue Growth, Profit Margins, Cash Flow.<br>2\. Highlight strengths and areas for improvement.<br></instructions><br>Make your tone concise and professional. Follow this structure:<br><formatting\_example>{{Q1\_REPORT}}</formatting\_example> |
| Assistant | Q2 Financial Report for AcmeCorp Investors<br>Dear Valued Investors,<br>I am pleased to present our Q2 financial report, showcasing AcmeCorp’s continued growth and resilience in the B2B SaaS market.<br>1\. Revenue Growth:<br>Our Q2 revenue reached $15.2M, a 22% YoY increase. This growth is primarily driven by a 30% expansion in our enterprise client base. However, our SMB segment saw a slight decline of 5%, which we aim to address through targeted marketing initiatives in Q3.<br>2\. Profit Margins:<br>Gross margin improved to 72% (up 3% from Q1) due to infrastructure optimizations. EBITDA margin, however, dipped to 18% (down 2%) as we invested heavily in R&D for our upcoming AI-driven features.<br>3\. Cash Flow:<br>Operating cash flow remains strong at $4.1M. Our cash reserves stand at $28M, providing a 15-month runway at current burn rate. We did see a 20% increase in customer acquisition costs, which we’re addressing through more efficient sales strategies.<br>In summary, AcmeCorp’s core financials remain robust. We’re balancing growth investments with prudent cash management. Our focus for Q3 will be revitalizing SMB growth and optimizing sales efficiency.<br>Thank you for your continued trust.<br>Sincerely,<br>CFO, AcmeCorp | Q2 Financial Report for AcmeCorp Investors</output><br>Revenue Growth:<br>\- Q2 revenue: $15.2M (22% YoY ↑)<br>\- Enterprise clients: 30% ↑<br>\- SMB segment: 5% ↓<br> Action: Targeted Q3 marketing<br>Profit Margins:<br>\- Gross margin: 72% (3% ↑ from Q1)<br> Reason: Infrastructure optimizations<br>\- EBITDA margin: 18% (2% ↓)<br> Reason: R&D investment in AI features<br>Cash Flow:<br>\- Operating cash flow: $4.1M (strong)<br>\- Cash reserves: $28M (15-month runway)<br>\- Customer acquisition cost: 20% ↑<br> Action: Optimize sales strategies<br>Outlook:<br>\- Core financials: Robust<br>\- Q3 focus: Revitalize SMB, optimize sales<br>Management remains committed to balancing growth investments with financial discipline. |

Example: Legal contract analysis

Without XML tags, Claude’s analysis is disorganized and misses key points. With tags, it provides a structured, thorough analysis that a legal team can act on.

| Role | No XML Tags | With XML Tags |
| --- | --- | --- |
| User | Analyze this software licensing agreement for potential risks and liabilities: {{CONTRACT}}. Focus on indemnification, limitation of liability, and IP ownership clauses. Also, note any unusual or concerning terms. Here’s our standard contract for reference: {{STANDARD\_CONTRACT}}. Give a summary of findings and recommendations for our legal team. | Analyze this software licensing agreement for legal risks and liabilities.<br>We’re a multinational enterprise considering this agreement for our core data infrastructure.<br><agreement><br>{{CONTRACT}}</agreement><br>This is our standard contract for reference:<br><standard\_contract>{{STANDARD\_CONTRACT}}</standard\_contract><br><instructions><br>1\. Analyze these clauses:<br> \- Indemnification<br> \- Limitation of liability<br> \- IP ownership<br>2\. Note unusual or concerning terms.<br>3\. Compare to our standard contract.<br>4\. Summarize findings in <findings> tags.<br>5\. List actionable recommendations in <recommendations> tags.</instructions> |
| Assistant | The provided software licensing agreement presents several concerning aspects. The indemnification clause is overly broad, potentially exposing us to significant liabilities. The limitation of liability section caps damages at a mere $500, which is inadequate for our enterprise-level usage. Regarding IP, the agreement grants the vendor joint ownership of any modifications or integrations we create.<br>In summary, this agreement is not in our best interest. It exposes us to undue risk, limits our recourse in case of failures, and compromises our intellectual property rights. I recommend renegotiating these terms or seeking alternative vendors. | <findings><br>1\. Indemnification (Clause 8):<br> \- Issue: Overly broad. We indemnify vendor against “any and all claims” arising from our use.<br> \- Risk: Could hold us liable even for vendor’s negligence or product defects.<br> \- Deviation: Our standard limits indemnity to claims arising from our violation of agreement.<br>2\. Limitation of Liability (Clause 9):<br> \- Issue: Caps all damages at $500, including direct damages.<br> \- Risk: Grossly inadequate for enterprise use. A critical failure could cost millions.<br> \- Deviation: Our standard allows for direct damages up to 12 months of fees paid.<br>3\. IP Ownership (Clause 12):<br> \- Issue: Grants vendor joint ownership of our modifications/integrations.<br> \- Risk: Vendor could use or sell our proprietary algorithms or data insights.<br> \- Deviation: Our standard retains full ownership of our work.<br>4\. Unusual Terms:<br> \- Clause 5.3: Vendor can use our usage data for “any purpose.”<br> \- Clause 7.2: Vendor can terminate for “convenience” with only 7 days’ notice.<br> \- Clause 11: No warranties of any kind, even for basic merchantability.<br></findings><br><recommendations><br>1\. Reject this agreement. Risks far outweigh benefits for an enterprise.<br>2\. Counter-propose:<br> \- Indemnification: Limit to claims arising from our violation of agreement.<br> \- Liability: Cap at 12 months’ fees for direct damages; negotiate for indirect.<br> \- IP: Full ownership of our modifications/integrations.<br> \- Data Use: Restrict to service improvement only.<br> \- Termination: Minimum 90 days’ notice; only for cause.<br> \- Warranties: Demand basic merchantability and fitness for purpose.<br>3\. If vendor refuses, explore alternative providers or in-house solutions.<br>4\. Engage legal counsel for contract negotiation given high stakes.<br></recommendations> |

* * *

[**Prompt library** \\
\\
Get inspired by a curated selection of prompts for various tasks and use cases.](https://docs.anthropic.com/en/resources/prompt-library/library) [**GitHub prompting tutorial** \\
\\
An example-filled tutorial that covers the prompt engineering concepts found in our docs.](https://github.com/anthropics/prompt-eng-interactive-tutorial) [**Google Sheets prompting tutorial** \\
\\
A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8)

Was this page helpful?

YesNo

[Let Claude think (CoT)](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought) [Give Claude a role (system prompts)](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts)

On this page

- [Why use XML tags?](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags#why-use-xml-tags%3F)
- [Tagging best practices](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags#tagging-best-practices)
- [Examples](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags#examples)
