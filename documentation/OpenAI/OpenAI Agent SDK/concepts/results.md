---
title: Results
source: https://openai.github.io/openai-agents-python/results/
---

# Results

When you call the `Runner.run` methods, you either get a:

- [`RunResult`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResult "RunResult            dataclass   ") if you call `run` or `run_sync`
- [`RunResultStreaming`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultStreaming "RunResultStreaming            dataclass   ") if you call `run_streamed`

Both of these inherit from [`RunResultBase`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultBase "RunResultBase            dataclass   "), which is where most useful information is present.

## Final output

The [`final_output`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultBase.final_output "final_output            instance-attribute   ") property contains the final output of the last agent that ran. This is either:

- a `str`, if the last agent didn't have an `output_type` defined
- an object of type `last_agent.output_type`, if the agent had an output type defined.

Note

`final_output` is of type `Any`. We can't statically type this, because of handoffs. If handoffs occur, that means any Agent might be the last agent, so we don't statically know the set of possible output types.

## Inputs for the next turn

You can use [`result.to_input_list()`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultBase.to_input_list "to_input_list") to turn the result into an input list that concatenates the original input you provided, to the items generated during the agent run. This makes it convenient to take the outputs of one agent run and pass them into another run, or to run it in a loop and append new user inputs each time.

## Last agent

The [`last_agent`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultBase.last_agent "last_agent            abstractmethod       property   ") property contains the last agent that ran. Depending on your application, this is often useful for the next time the user inputs something. For example, if you have a frontline triage agent that hands off to a language-specific agent, you can store the last agent, and re-use it the next time the user messages the agent.

## New items

The [`new_items`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultBase.new_items "new_items            instance-attribute   ") property contains the new items generated during the run. The items are [`RunItem`](https://openai.github.io/openai-agents-python/ref/items/#agents.items.RunItem "RunItem            module-attribute   ") s. A run item wraps the raw item generated by the LLM.

- [`MessageOutputItem`](https://openai.github.io/openai-agents-python/ref/items/#agents.items.MessageOutputItem "MessageOutputItem            dataclass   ") indicates a message from the LLM. The raw item is the message generated.
- [`HandoffCallItem`](https://openai.github.io/openai-agents-python/ref/items/#agents.items.HandoffCallItem "HandoffCallItem            dataclass   ") indicates that the LLM called the handoff tool. The raw item is the tool call item from the LLM.
- [`HandoffOutputItem`](https://openai.github.io/openai-agents-python/ref/items/#agents.items.HandoffOutputItem "HandoffOutputItem            dataclass   ") indicates that a handoff occurred. The raw item is the tool response to the handoff tool call. You can also access the source/target agents from the item.
- [`ToolCallItem`](https://openai.github.io/openai-agents-python/ref/items/#agents.items.ToolCallItem "ToolCallItem            dataclass   ") indicates that the LLM invoked a tool.
- [`ToolCallOutputItem`](https://openai.github.io/openai-agents-python/ref/items/#agents.items.ToolCallOutputItem "ToolCallOutputItem            dataclass   ") indicates that a tool was called. The raw item is the tool response. You can also access the tool output from the item.
- [`ReasoningItem`](https://openai.github.io/openai-agents-python/ref/items/#agents.items.ReasoningItem "ReasoningItem            dataclass   ") indicates a reasoning item from the LLM. The raw item is the reasoning generated.

## Other information

### Guardrail results

The [`input_guardrail_results`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultBase.input_guardrail_results "input_guardrail_results            instance-attribute   ") and [`output_guardrail_results`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultBase.output_guardrail_results "output_guardrail_results            instance-attribute   ") properties contain the results of the guardrails, if any. Guardrail results can sometimes contain useful information you want to log or store, so we make these available to you.

### Raw responses

The [`raw_responses`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultBase.raw_responses "raw_responses            instance-attribute   ") property contains the [`ModelResponse`](https://openai.github.io/openai-agents-python/ref/items/#agents.items.ModelResponse "ModelResponse") s generated by the LLM.

### Original input

The [`input`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultBase.input "input            instance-attribute   ") property contains the original input you provided to the `run` method. In most cases you won't need this, but it's available in case you do.